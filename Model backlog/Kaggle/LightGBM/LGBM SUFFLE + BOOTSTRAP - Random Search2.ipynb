{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": false,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "sns.set()\n",
    "PATH=\"../input/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "X_train_df = pd.read_csv(PATH+\"/X_train.csv\")\n",
    "X_test_df = pd.read_csv(PATH+\"/X_test.csv\")\n",
    "Y_train_df = pd.read_csv(PATH+\"/y_train.csv\")\n",
    "target = pd.read_csv(PATH+'/y_train.csv')\n",
    "sub = pd.read_csv(PATH+\"/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New features:  168\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orientation_X_mean</th>\n",
       "      <th>orientation_X_median</th>\n",
       "      <th>orientation_X_max</th>\n",
       "      <th>orientation_X_min</th>\n",
       "      <th>orientation_X_std</th>\n",
       "      <th>orientation_X_range</th>\n",
       "      <th>orientation_X_maxtoMin</th>\n",
       "      <th>orientation_X_mean_abs_chg</th>\n",
       "      <th>orientation_X_mean_change_of_abs_change</th>\n",
       "      <th>orientation_X_abs_max</th>\n",
       "      <th>orientation_X_abs_min</th>\n",
       "      <th>orientation_X_abs_avg</th>\n",
       "      <th>orientation_Y_mean</th>\n",
       "      <th>orientation_Y_median</th>\n",
       "      <th>orientation_Y_max</th>\n",
       "      <th>orientation_Y_min</th>\n",
       "      <th>orientation_Y_std</th>\n",
       "      <th>orientation_Y_range</th>\n",
       "      <th>orientation_Y_maxtoMin</th>\n",
       "      <th>orientation_Y_mean_abs_chg</th>\n",
       "      <th>orientation_Y_mean_change_of_abs_change</th>\n",
       "      <th>orientation_Y_abs_max</th>\n",
       "      <th>orientation_Y_abs_min</th>\n",
       "      <th>orientation_Y_abs_avg</th>\n",
       "      <th>orientation_Z_mean</th>\n",
       "      <th>orientation_Z_median</th>\n",
       "      <th>orientation_Z_max</th>\n",
       "      <th>orientation_Z_min</th>\n",
       "      <th>orientation_Z_std</th>\n",
       "      <th>orientation_Z_range</th>\n",
       "      <th>orientation_Z_maxtoMin</th>\n",
       "      <th>orientation_Z_mean_abs_chg</th>\n",
       "      <th>orientation_Z_mean_change_of_abs_change</th>\n",
       "      <th>orientation_Z_abs_max</th>\n",
       "      <th>orientation_Z_abs_min</th>\n",
       "      <th>orientation_Z_abs_avg</th>\n",
       "      <th>orientation_W_mean</th>\n",
       "      <th>orientation_W_median</th>\n",
       "      <th>orientation_W_max</th>\n",
       "      <th>orientation_W_min</th>\n",
       "      <th>...</th>\n",
       "      <th>totl_anglr_vel_mean_change_of_abs_change</th>\n",
       "      <th>totl_anglr_vel_abs_max</th>\n",
       "      <th>totl_anglr_vel_abs_min</th>\n",
       "      <th>totl_anglr_vel_abs_avg</th>\n",
       "      <th>totl_linr_acc_mean</th>\n",
       "      <th>totl_linr_acc_median</th>\n",
       "      <th>totl_linr_acc_max</th>\n",
       "      <th>totl_linr_acc_min</th>\n",
       "      <th>totl_linr_acc_std</th>\n",
       "      <th>totl_linr_acc_range</th>\n",
       "      <th>totl_linr_acc_maxtoMin</th>\n",
       "      <th>totl_linr_acc_mean_abs_chg</th>\n",
       "      <th>totl_linr_acc_mean_change_of_abs_change</th>\n",
       "      <th>totl_linr_acc_abs_max</th>\n",
       "      <th>totl_linr_acc_abs_min</th>\n",
       "      <th>totl_linr_acc_abs_avg</th>\n",
       "      <th>totl_xyz_mean</th>\n",
       "      <th>totl_xyz_median</th>\n",
       "      <th>totl_xyz_max</th>\n",
       "      <th>totl_xyz_min</th>\n",
       "      <th>totl_xyz_std</th>\n",
       "      <th>totl_xyz_range</th>\n",
       "      <th>totl_xyz_maxtoMin</th>\n",
       "      <th>totl_xyz_mean_abs_chg</th>\n",
       "      <th>totl_xyz_mean_change_of_abs_change</th>\n",
       "      <th>totl_xyz_abs_max</th>\n",
       "      <th>totl_xyz_abs_min</th>\n",
       "      <th>totl_xyz_abs_avg</th>\n",
       "      <th>acc_vs_vel_mean</th>\n",
       "      <th>acc_vs_vel_median</th>\n",
       "      <th>acc_vs_vel_max</th>\n",
       "      <th>acc_vs_vel_min</th>\n",
       "      <th>acc_vs_vel_std</th>\n",
       "      <th>acc_vs_vel_range</th>\n",
       "      <th>acc_vs_vel_maxtoMin</th>\n",
       "      <th>acc_vs_vel_mean_abs_chg</th>\n",
       "      <th>acc_vs_vel_mean_change_of_abs_change</th>\n",
       "      <th>acc_vs_vel_abs_max</th>\n",
       "      <th>acc_vs_vel_abs_min</th>\n",
       "      <th>acc_vs_vel_abs_avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.758666</td>\n",
       "      <td>-0.758530</td>\n",
       "      <td>-0.75822</td>\n",
       "      <td>-0.75953</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.00131</td>\n",
       "      <td>0.998275</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>2.380952e-07</td>\n",
       "      <td>0.75953</td>\n",
       "      <td>0.75822</td>\n",
       "      <td>0.758875</td>\n",
       "      <td>-0.634008</td>\n",
       "      <td>-0.634270</td>\n",
       "      <td>-0.63306</td>\n",
       "      <td>-0.63456</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>0.997636</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.63456</td>\n",
       "      <td>0.63306</td>\n",
       "      <td>0.633810</td>\n",
       "      <td>-0.105474</td>\n",
       "      <td>-0.105500</td>\n",
       "      <td>-0.104610</td>\n",
       "      <td>-0.106140</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.985585</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>7.936508e-08</td>\n",
       "      <td>0.106140</td>\n",
       "      <td>0.104610</td>\n",
       "      <td>0.105375</td>\n",
       "      <td>-0.106470</td>\n",
       "      <td>-0.106555</td>\n",
       "      <td>-0.105590</td>\n",
       "      <td>-0.107050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.162384</td>\n",
       "      <td>0.010603</td>\n",
       "      <td>0.086494</td>\n",
       "      <td>9.939676</td>\n",
       "      <td>10.077860</td>\n",
       "      <td>12.575577</td>\n",
       "      <td>7.117152</td>\n",
       "      <td>0.989642</td>\n",
       "      <td>5.458424</td>\n",
       "      <td>1.766939</td>\n",
       "      <td>0.689030</td>\n",
       "      <td>0.006324</td>\n",
       "      <td>12.575577</td>\n",
       "      <td>7.117152</td>\n",
       "      <td>9.846364</td>\n",
       "      <td>0.994316</td>\n",
       "      <td>0.994306</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>1.000161</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>7.240501e-08</td>\n",
       "      <td>0.994413</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.994333</td>\n",
       "      <td>223.282937</td>\n",
       "      <td>187.471573</td>\n",
       "      <td>995.561076</td>\n",
       "      <td>56.133014</td>\n",
       "      <td>135.641510</td>\n",
       "      <td>939.428062</td>\n",
       "      <td>17.735749</td>\n",
       "      <td>114.896199</td>\n",
       "      <td>1.309785</td>\n",
       "      <td>995.561076</td>\n",
       "      <td>56.133014</td>\n",
       "      <td>525.847045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.958606</td>\n",
       "      <td>-0.958595</td>\n",
       "      <td>-0.95837</td>\n",
       "      <td>-0.95896</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.00059</td>\n",
       "      <td>0.999385</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-4.761905e-07</td>\n",
       "      <td>0.95896</td>\n",
       "      <td>0.95837</td>\n",
       "      <td>0.958665</td>\n",
       "      <td>0.241867</td>\n",
       "      <td>0.241890</td>\n",
       "      <td>0.24270</td>\n",
       "      <td>0.24074</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.00196</td>\n",
       "      <td>1.008142</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>1.587302e-07</td>\n",
       "      <td>0.24270</td>\n",
       "      <td>0.24074</td>\n",
       "      <td>0.241720</td>\n",
       "      <td>0.031650</td>\n",
       "      <td>0.031688</td>\n",
       "      <td>0.032341</td>\n",
       "      <td>0.030504</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>1.060222</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>3.253968e-07</td>\n",
       "      <td>0.032341</td>\n",
       "      <td>0.030504</td>\n",
       "      <td>0.031423</td>\n",
       "      <td>-0.146876</td>\n",
       "      <td>-0.146910</td>\n",
       "      <td>-0.145870</td>\n",
       "      <td>-0.148090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001095</td>\n",
       "      <td>0.287947</td>\n",
       "      <td>0.020167</td>\n",
       "      <td>0.154057</td>\n",
       "      <td>10.082444</td>\n",
       "      <td>10.069950</td>\n",
       "      <td>16.986332</td>\n",
       "      <td>5.867993</td>\n",
       "      <td>1.826016</td>\n",
       "      <td>11.118339</td>\n",
       "      <td>2.894743</td>\n",
       "      <td>1.361058</td>\n",
       "      <td>-0.018901</td>\n",
       "      <td>16.986332</td>\n",
       "      <td>5.867993</td>\n",
       "      <td>11.427163</td>\n",
       "      <td>0.989155</td>\n",
       "      <td>0.989150</td>\n",
       "      <td>0.989305</td>\n",
       "      <td>0.988974</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>1.000334</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-2.398138e-07</td>\n",
       "      <td>0.989305</td>\n",
       "      <td>0.988974</td>\n",
       "      <td>0.989139</td>\n",
       "      <td>118.973908</td>\n",
       "      <td>98.477877</td>\n",
       "      <td>611.826712</td>\n",
       "      <td>32.938319</td>\n",
       "      <td>88.488750</td>\n",
       "      <td>578.888393</td>\n",
       "      <td>18.574922</td>\n",
       "      <td>57.943094</td>\n",
       "      <td>0.508448</td>\n",
       "      <td>611.826712</td>\n",
       "      <td>32.938319</td>\n",
       "      <td>322.382516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.512057</td>\n",
       "      <td>-0.512035</td>\n",
       "      <td>-0.50944</td>\n",
       "      <td>-0.51434</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>0.00490</td>\n",
       "      <td>0.990473</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.51434</td>\n",
       "      <td>0.50944</td>\n",
       "      <td>0.511890</td>\n",
       "      <td>-0.846171</td>\n",
       "      <td>-0.846210</td>\n",
       "      <td>-0.84490</td>\n",
       "      <td>-0.84779</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.00289</td>\n",
       "      <td>0.996591</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-7.142857e-07</td>\n",
       "      <td>0.84779</td>\n",
       "      <td>0.84490</td>\n",
       "      <td>0.846345</td>\n",
       "      <td>-0.129371</td>\n",
       "      <td>-0.129405</td>\n",
       "      <td>-0.128520</td>\n",
       "      <td>-0.130300</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.986339</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>-1.746032e-06</td>\n",
       "      <td>0.130300</td>\n",
       "      <td>0.128520</td>\n",
       "      <td>0.129410</td>\n",
       "      <td>-0.071082</td>\n",
       "      <td>-0.071139</td>\n",
       "      <td>-0.070378</td>\n",
       "      <td>-0.071535</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000471</td>\n",
       "      <td>0.170919</td>\n",
       "      <td>0.009871</td>\n",
       "      <td>0.090395</td>\n",
       "      <td>10.035741</td>\n",
       "      <td>10.082289</td>\n",
       "      <td>12.725500</td>\n",
       "      <td>6.794325</td>\n",
       "      <td>0.944637</td>\n",
       "      <td>5.931175</td>\n",
       "      <td>1.872960</td>\n",
       "      <td>0.711678</td>\n",
       "      <td>-0.001612</td>\n",
       "      <td>12.725500</td>\n",
       "      <td>6.794325</td>\n",
       "      <td>9.759913</td>\n",
       "      <td>0.997471</td>\n",
       "      <td>0.997467</td>\n",
       "      <td>0.997515</td>\n",
       "      <td>0.997438</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>1.000078</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-1.068346e-07</td>\n",
       "      <td>0.997515</td>\n",
       "      <td>0.997438</td>\n",
       "      <td>0.997477</td>\n",
       "      <td>190.134237</td>\n",
       "      <td>146.667138</td>\n",
       "      <td>904.269577</td>\n",
       "      <td>52.834789</td>\n",
       "      <td>132.789650</td>\n",
       "      <td>851.434788</td>\n",
       "      <td>17.115041</td>\n",
       "      <td>83.878164</td>\n",
       "      <td>-0.078679</td>\n",
       "      <td>904.269577</td>\n",
       "      <td>52.834789</td>\n",
       "      <td>478.552183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.939169</td>\n",
       "      <td>-0.939170</td>\n",
       "      <td>-0.93884</td>\n",
       "      <td>-0.93968</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.00084</td>\n",
       "      <td>0.999106</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-6.349206e-07</td>\n",
       "      <td>0.93968</td>\n",
       "      <td>0.93884</td>\n",
       "      <td>0.939260</td>\n",
       "      <td>0.310140</td>\n",
       "      <td>0.310115</td>\n",
       "      <td>0.31147</td>\n",
       "      <td>0.30943</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>1.006593</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.31147</td>\n",
       "      <td>0.30943</td>\n",
       "      <td>0.310450</td>\n",
       "      <td>0.038955</td>\n",
       "      <td>0.038889</td>\n",
       "      <td>0.039799</td>\n",
       "      <td>0.037922</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.001877</td>\n",
       "      <td>1.049496</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>-8.412698e-07</td>\n",
       "      <td>0.039799</td>\n",
       "      <td>0.037922</td>\n",
       "      <td>0.038861</td>\n",
       "      <td>-0.142319</td>\n",
       "      <td>-0.142510</td>\n",
       "      <td>-0.139340</td>\n",
       "      <td>-0.144370</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001416</td>\n",
       "      <td>0.523568</td>\n",
       "      <td>0.014446</td>\n",
       "      <td>0.269007</td>\n",
       "      <td>10.888094</td>\n",
       "      <td>10.925683</td>\n",
       "      <td>20.833299</td>\n",
       "      <td>2.064233</td>\n",
       "      <td>3.102236</td>\n",
       "      <td>18.769065</td>\n",
       "      <td>10.092512</td>\n",
       "      <td>2.203234</td>\n",
       "      <td>-0.066505</td>\n",
       "      <td>20.833299</td>\n",
       "      <td>2.064233</td>\n",
       "      <td>11.448766</td>\n",
       "      <td>0.989820</td>\n",
       "      <td>0.989793</td>\n",
       "      <td>0.990242</td>\n",
       "      <td>0.989525</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>1.000725</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-5.698913e-07</td>\n",
       "      <td>0.990242</td>\n",
       "      <td>0.989525</td>\n",
       "      <td>0.989884</td>\n",
       "      <td>115.134804</td>\n",
       "      <td>84.403391</td>\n",
       "      <td>805.924410</td>\n",
       "      <td>11.305069</td>\n",
       "      <td>112.264757</td>\n",
       "      <td>794.619341</td>\n",
       "      <td>71.288762</td>\n",
       "      <td>76.773215</td>\n",
       "      <td>0.928182</td>\n",
       "      <td>805.924410</td>\n",
       "      <td>11.305069</td>\n",
       "      <td>408.614740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.891301</td>\n",
       "      <td>-0.890940</td>\n",
       "      <td>-0.88673</td>\n",
       "      <td>-0.89689</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.01016</td>\n",
       "      <td>0.988672</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>7.936508e-08</td>\n",
       "      <td>0.89689</td>\n",
       "      <td>0.88673</td>\n",
       "      <td>0.891810</td>\n",
       "      <td>0.428144</td>\n",
       "      <td>0.428865</td>\n",
       "      <td>0.43740</td>\n",
       "      <td>0.41646</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.02094</td>\n",
       "      <td>1.050281</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>2.380952e-07</td>\n",
       "      <td>0.43740</td>\n",
       "      <td>0.41646</td>\n",
       "      <td>0.426930</td>\n",
       "      <td>0.060056</td>\n",
       "      <td>0.060113</td>\n",
       "      <td>0.061771</td>\n",
       "      <td>0.058247</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.003524</td>\n",
       "      <td>1.060501</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>3.174603e-08</td>\n",
       "      <td>0.061771</td>\n",
       "      <td>0.058247</td>\n",
       "      <td>0.060009</td>\n",
       "      <td>-0.136460</td>\n",
       "      <td>-0.136560</td>\n",
       "      <td>-0.135380</td>\n",
       "      <td>-0.137320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.231539</td>\n",
       "      <td>0.091379</td>\n",
       "      <td>0.161459</td>\n",
       "      <td>9.892815</td>\n",
       "      <td>10.005620</td>\n",
       "      <td>11.485482</td>\n",
       "      <td>8.071708</td>\n",
       "      <td>0.765162</td>\n",
       "      <td>3.413774</td>\n",
       "      <td>1.422931</td>\n",
       "      <td>0.521694</td>\n",
       "      <td>-0.001280</td>\n",
       "      <td>11.485482</td>\n",
       "      <td>8.071708</td>\n",
       "      <td>9.778595</td>\n",
       "      <td>0.990645</td>\n",
       "      <td>0.990633</td>\n",
       "      <td>0.990796</td>\n",
       "      <td>0.990524</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>1.000275</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.740516e-09</td>\n",
       "      <td>0.990796</td>\n",
       "      <td>0.990524</td>\n",
       "      <td>0.990660</td>\n",
       "      <td>66.057675</td>\n",
       "      <td>61.430180</td>\n",
       "      <td>111.588333</td>\n",
       "      <td>39.895232</td>\n",
       "      <td>16.611029</td>\n",
       "      <td>71.693101</td>\n",
       "      <td>2.797034</td>\n",
       "      <td>5.618844</td>\n",
       "      <td>-0.003968</td>\n",
       "      <td>111.588333</td>\n",
       "      <td>39.895232</td>\n",
       "      <td>75.741783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           orientation_X_mean         ...          acc_vs_vel_abs_avg\n",
       "series_id                             ...                            \n",
       "0                   -0.758666         ...                  525.847045\n",
       "1                   -0.958606         ...                  322.382516\n",
       "2                   -0.512057         ...                  478.552183\n",
       "3                   -0.939169         ...                  408.614740\n",
       "4                   -0.891301         ...                   75.741783\n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fe(data):\n",
    "    df = pd.DataFrame()\n",
    "    data['totl_anglr_vel'] = (data['angular_velocity_X']**2 + data['angular_velocity_Y']**2 + data['angular_velocity_Z']**2)** 0.5\n",
    "    data['totl_linr_acc'] = (data['linear_acceleration_X']**2 + data['linear_acceleration_Y']**2 + data['linear_acceleration_Z']**2)**0.5\n",
    "    data['totl_xyz'] = (data['orientation_X']**2 + data['orientation_Y']**2 + data['orientation_Z']**2)**0.5\n",
    "    data['acc_vs_vel'] = data['totl_linr_acc'] / data['totl_anglr_vel']\n",
    "    \n",
    "    def mean_change_of_abs_change(x):\n",
    "        return np.mean(np.diff(np.abs(np.diff(x))))\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if col in ['row_id','series_id','measurement_number']:\n",
    "            continue\n",
    "        df[col + '_mean'] = data.groupby(['series_id'])[col].mean()\n",
    "        df[col + '_median'] = data.groupby(['series_id'])[col].median()\n",
    "        df[col + '_max'] = data.groupby(['series_id'])[col].max()\n",
    "        df[col + '_min'] = data.groupby(['series_id'])[col].min()\n",
    "        df[col + '_std'] = data.groupby(['series_id'])[col].std()\n",
    "        df[col + '_range'] = df[col + '_max'] - df[col + '_min']\n",
    "        df[col + '_maxtoMin'] = df[col + '_max'] / df[col + '_min']\n",
    "        df[col + '_mean_abs_chg'] = data.groupby(['series_id'])[col].apply(lambda x: np.mean(np.abs(np.diff(x))))\n",
    "        df[col + '_mean_change_of_abs_change'] = data.groupby('series_id')[col].apply(mean_change_of_abs_change)\n",
    "        df[col + '_abs_max'] = data.groupby(['series_id'])[col].apply(lambda x: np.max(np.abs(x)))\n",
    "        df[col + '_abs_min'] = data.groupby(['series_id'])[col].apply(lambda x: np.min(np.abs(x)))\n",
    "        df[col + '_abs_avg'] = (df[col + '_abs_min'] + df[col + '_abs_max'])/2\n",
    "    return df\n",
    "\n",
    "train_df = fe(X_train_df)\n",
    "test_df = fe(X_test_df)\n",
    "print (\"New features: \",train_df.shape[1])\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filling missing NAs and infinite data ∞  by zeroes 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "train_df.fillna(0, inplace = True)\n",
    "train_df.replace(-np.inf, 0, inplace = True)\n",
    "train_df.replace(np.inf, 0, inplace = True)\n",
    "test_df.fillna(0, inplace = True)\n",
    "test_df.replace(-np.inf, 0, inplace = True)\n",
    "test_df.replace(np.inf, 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "      <th>151</th>\n",
       "      <th>152</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>162</th>\n",
       "      <th>163</th>\n",
       "      <th>164</th>\n",
       "      <th>165</th>\n",
       "      <th>166</th>\n",
       "      <th>167</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.080161</td>\n",
       "      <td>-1.079898</td>\n",
       "      <td>-1.089366</td>\n",
       "      <td>-1.071550</td>\n",
       "      <td>-0.601727</td>\n",
       "      <td>-0.599121</td>\n",
       "      <td>-0.021421</td>\n",
       "      <td>-0.658087</td>\n",
       "      <td>0.320344</td>\n",
       "      <td>0.455900</td>\n",
       "      <td>0.490939</td>\n",
       "      <td>0.473909</td>\n",
       "      <td>-1.001245</td>\n",
       "      <td>-1.001569</td>\n",
       "      <td>-1.010113</td>\n",
       "      <td>-0.991812</td>\n",
       "      <td>-0.565439</td>\n",
       "      <td>-0.571679</td>\n",
       "      <td>-0.023780</td>\n",
       "      <td>-0.625298</td>\n",
       "      <td>0.015239</td>\n",
       "      <td>-0.102595</td>\n",
       "      <td>-0.057877</td>\n",
       "      <td>-0.080044</td>\n",
       "      <td>-1.112937</td>\n",
       "      <td>-1.113125</td>\n",
       "      <td>-1.120509</td>\n",
       "      <td>-1.103174</td>\n",
       "      <td>-0.506429</td>\n",
       "      <td>-0.561239</td>\n",
       "      <td>-0.016587</td>\n",
       "      <td>-0.531159</td>\n",
       "      <td>0.093718</td>\n",
       "      <td>0.162439</td>\n",
       "      <td>0.200247</td>\n",
       "      <td>0.181548</td>\n",
       "      <td>-0.984416</td>\n",
       "      <td>-0.985289</td>\n",
       "      <td>-0.991948</td>\n",
       "      <td>-0.973604</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110298</td>\n",
       "      <td>-0.828980</td>\n",
       "      <td>-0.519549</td>\n",
       "      <td>-0.808956</td>\n",
       "      <td>-0.438068</td>\n",
       "      <td>-0.138938</td>\n",
       "      <td>-0.506246</td>\n",
       "      <td>0.380762</td>\n",
       "      <td>-0.542346</td>\n",
       "      <td>-0.501756</td>\n",
       "      <td>-0.450044</td>\n",
       "      <td>-0.563804</td>\n",
       "      <td>0.346558</td>\n",
       "      <td>-0.506246</td>\n",
       "      <td>0.380762</td>\n",
       "      <td>-0.477901</td>\n",
       "      <td>-0.055780</td>\n",
       "      <td>-0.058710</td>\n",
       "      <td>-0.070205</td>\n",
       "      <td>-0.031780</td>\n",
       "      <td>-0.517863</td>\n",
       "      <td>-0.536448</td>\n",
       "      <td>-0.536751</td>\n",
       "      <td>-0.435900</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>-0.070205</td>\n",
       "      <td>-0.031780</td>\n",
       "      <td>-0.050778</td>\n",
       "      <td>0.265845</td>\n",
       "      <td>0.283442</td>\n",
       "      <td>0.143058</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>0.176173</td>\n",
       "      <td>0.146469</td>\n",
       "      <td>-0.113058</td>\n",
       "      <td>0.328904</td>\n",
       "      <td>0.434328</td>\n",
       "      <td>0.143058</td>\n",
       "      <td>0.063600</td>\n",
       "      <td>0.139838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.371767</td>\n",
       "      <td>-1.371667</td>\n",
       "      <td>-1.381118</td>\n",
       "      <td>-1.362565</td>\n",
       "      <td>-0.634918</td>\n",
       "      <td>-0.632274</td>\n",
       "      <td>-0.021024</td>\n",
       "      <td>-0.608125</td>\n",
       "      <td>-0.614629</td>\n",
       "      <td>1.159574</td>\n",
       "      <td>1.182335</td>\n",
       "      <td>1.171828</td>\n",
       "      <td>0.235538</td>\n",
       "      <td>0.235553</td>\n",
       "      <td>0.227341</td>\n",
       "      <td>0.243307</td>\n",
       "      <td>-0.560947</td>\n",
       "      <td>-0.549754</td>\n",
       "      <td>-0.009432</td>\n",
       "      <td>-0.303394</td>\n",
       "      <td>0.193113</td>\n",
       "      <td>-1.531669</td>\n",
       "      <td>-1.457922</td>\n",
       "      <td>-1.495349</td>\n",
       "      <td>0.181123</td>\n",
       "      <td>0.181503</td>\n",
       "      <td>0.172285</td>\n",
       "      <td>0.185607</td>\n",
       "      <td>-0.422277</td>\n",
       "      <td>-0.461943</td>\n",
       "      <td>0.057252</td>\n",
       "      <td>-0.569790</td>\n",
       "      <td>0.310939</td>\n",
       "      <td>-1.548991</td>\n",
       "      <td>-1.500975</td>\n",
       "      <td>-1.525783</td>\n",
       "      <td>-1.371850</td>\n",
       "      <td>-1.372237</td>\n",
       "      <td>-1.378102</td>\n",
       "      <td>-1.367066</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.985190</td>\n",
       "      <td>-0.328703</td>\n",
       "      <td>-0.460865</td>\n",
       "      <td>-0.435543</td>\n",
       "      <td>-0.264644</td>\n",
       "      <td>-0.153011</td>\n",
       "      <td>0.139224</td>\n",
       "      <td>-0.167213</td>\n",
       "      <td>0.015843</td>\n",
       "      <td>0.154509</td>\n",
       "      <td>-0.193142</td>\n",
       "      <td>0.057404</td>\n",
       "      <td>-1.025177</td>\n",
       "      <td>0.139224</td>\n",
       "      <td>-0.167213</td>\n",
       "      <td>0.105154</td>\n",
       "      <td>-1.395270</td>\n",
       "      <td>-1.396747</td>\n",
       "      <td>-1.412234</td>\n",
       "      <td>-1.384291</td>\n",
       "      <td>-0.044975</td>\n",
       "      <td>0.101798</td>\n",
       "      <td>0.106778</td>\n",
       "      <td>0.615510</td>\n",
       "      <td>-1.604895</td>\n",
       "      <td>-1.412234</td>\n",
       "      <td>-1.384291</td>\n",
       "      <td>-1.398817</td>\n",
       "      <td>-0.098028</td>\n",
       "      <td>-0.098567</td>\n",
       "      <td>-0.075991</td>\n",
       "      <td>-0.166719</td>\n",
       "      <td>-0.045048</td>\n",
       "      <td>-0.069773</td>\n",
       "      <td>-0.084434</td>\n",
       "      <td>-0.031030</td>\n",
       "      <td>0.176977</td>\n",
       "      <td>-0.075991</td>\n",
       "      <td>-0.166719</td>\n",
       "      <td>-0.081564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.720492</td>\n",
       "      <td>-0.720416</td>\n",
       "      <td>-0.726728</td>\n",
       "      <td>-0.713761</td>\n",
       "      <td>-0.442364</td>\n",
       "      <td>-0.433818</td>\n",
       "      <td>-0.024209</td>\n",
       "      <td>-0.504431</td>\n",
       "      <td>0.008686</td>\n",
       "      <td>-0.409235</td>\n",
       "      <td>-0.368445</td>\n",
       "      <td>-0.388873</td>\n",
       "      <td>-1.300831</td>\n",
       "      <td>-1.300824</td>\n",
       "      <td>-1.309444</td>\n",
       "      <td>-1.292697</td>\n",
       "      <td>-0.514383</td>\n",
       "      <td>-0.505429</td>\n",
       "      <td>-0.025207</td>\n",
       "      <td>-0.587312</td>\n",
       "      <td>-0.785193</td>\n",
       "      <td>0.675033</td>\n",
       "      <td>0.698102</td>\n",
       "      <td>0.687131</td>\n",
       "      <td>-1.338451</td>\n",
       "      <td>-1.338713</td>\n",
       "      <td>-1.346215</td>\n",
       "      <td>-1.331043</td>\n",
       "      <td>-0.386707</td>\n",
       "      <td>-0.480379</td>\n",
       "      <td>-0.015841</td>\n",
       "      <td>-0.394443</td>\n",
       "      <td>-1.517920</td>\n",
       "      <td>0.722719</td>\n",
       "      <td>0.749139</td>\n",
       "      <td>0.736441</td>\n",
       "      <td>-0.645099</td>\n",
       "      <td>-0.645704</td>\n",
       "      <td>-0.654379</td>\n",
       "      <td>-0.633113</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.860744</td>\n",
       "      <td>-0.794975</td>\n",
       "      <td>-0.524041</td>\n",
       "      <td>-0.787394</td>\n",
       "      <td>-0.321376</td>\n",
       "      <td>-0.131055</td>\n",
       "      <td>-0.484306</td>\n",
       "      <td>0.239146</td>\n",
       "      <td>-0.572382</td>\n",
       "      <td>-0.446941</td>\n",
       "      <td>-0.425894</td>\n",
       "      <td>-0.542869</td>\n",
       "      <td>-0.085028</td>\n",
       "      <td>-0.484306</td>\n",
       "      <td>0.239146</td>\n",
       "      <td>-0.509787</td>\n",
       "      <td>0.762893</td>\n",
       "      <td>0.761582</td>\n",
       "      <td>0.744711</td>\n",
       "      <td>0.784130</td>\n",
       "      <td>-0.811615</td>\n",
       "      <td>-0.845474</td>\n",
       "      <td>-0.846069</td>\n",
       "      <td>-0.631787</td>\n",
       "      <td>-0.685730</td>\n",
       "      <td>0.744711</td>\n",
       "      <td>0.784130</td>\n",
       "      <td>0.765066</td>\n",
       "      <td>0.150209</td>\n",
       "      <td>0.108287</td>\n",
       "      <td>0.090946</td>\n",
       "      <td>0.030849</td>\n",
       "      <td>0.162793</td>\n",
       "      <td>0.093693</td>\n",
       "      <td>-0.134230</td>\n",
       "      <td>0.132875</td>\n",
       "      <td>-0.011580</td>\n",
       "      <td>0.090946</td>\n",
       "      <td>0.030849</td>\n",
       "      <td>0.088373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.343418</td>\n",
       "      <td>-1.343338</td>\n",
       "      <td>-1.352650</td>\n",
       "      <td>-1.334431</td>\n",
       "      <td>-0.622987</td>\n",
       "      <td>-0.620762</td>\n",
       "      <td>-0.021124</td>\n",
       "      <td>-0.593042</td>\n",
       "      <td>-0.822400</td>\n",
       "      <td>1.091546</td>\n",
       "      <td>1.114871</td>\n",
       "      <td>1.104041</td>\n",
       "      <td>0.331943</td>\n",
       "      <td>0.331885</td>\n",
       "      <td>0.324513</td>\n",
       "      <td>0.340235</td>\n",
       "      <td>-0.568385</td>\n",
       "      <td>-0.545941</td>\n",
       "      <td>-0.011547</td>\n",
       "      <td>-0.513776</td>\n",
       "      <td>0.015239</td>\n",
       "      <td>-1.280872</td>\n",
       "      <td>-1.212793</td>\n",
       "      <td>-1.247259</td>\n",
       "      <td>0.250059</td>\n",
       "      <td>0.249453</td>\n",
       "      <td>0.242687</td>\n",
       "      <td>0.255571</td>\n",
       "      <td>-0.487298</td>\n",
       "      <td>-0.449005</td>\n",
       "      <td>0.046641</td>\n",
       "      <td>-0.294226</td>\n",
       "      <td>-0.719108</td>\n",
       "      <td>-1.376037</td>\n",
       "      <td>-1.330683</td>\n",
       "      <td>-1.354062</td>\n",
       "      <td>-1.328158</td>\n",
       "      <td>-1.330047</td>\n",
       "      <td>-1.315500</td>\n",
       "      <td>-1.331401</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.564965</td>\n",
       "      <td>0.610081</td>\n",
       "      <td>-0.495970</td>\n",
       "      <td>0.199770</td>\n",
       "      <td>0.713997</td>\n",
       "      <td>1.369603</td>\n",
       "      <td>0.702189</td>\n",
       "      <td>-1.835827</td>\n",
       "      <td>0.867582</td>\n",
       "      <td>1.041608</td>\n",
       "      <td>1.446434</td>\n",
       "      <td>0.835892</td>\n",
       "      <td>-3.613862</td>\n",
       "      <td>0.702189</td>\n",
       "      <td>-1.835827</td>\n",
       "      <td>0.113122</td>\n",
       "      <td>-1.222779</td>\n",
       "      <td>-1.229836</td>\n",
       "      <td>-1.165890</td>\n",
       "      <td>-1.243069</td>\n",
       "      <td>1.557698</td>\n",
       "      <td>1.549777</td>\n",
       "      <td>1.557993</td>\n",
       "      <td>1.955596</td>\n",
       "      <td>-3.886422</td>\n",
       "      <td>-1.165890</td>\n",
       "      <td>-1.243069</td>\n",
       "      <td>-1.205591</td>\n",
       "      <td>-0.111420</td>\n",
       "      <td>-0.158983</td>\n",
       "      <td>0.034807</td>\n",
       "      <td>-0.381534</td>\n",
       "      <td>0.066499</td>\n",
       "      <td>0.059617</td>\n",
       "      <td>1.713603</td>\n",
       "      <td>0.087973</td>\n",
       "      <td>0.311775</td>\n",
       "      <td>0.034807</td>\n",
       "      <td>-0.381534</td>\n",
       "      <td>0.012270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.273604</td>\n",
       "      <td>-1.273001</td>\n",
       "      <td>-1.276691</td>\n",
       "      <td>-1.271991</td>\n",
       "      <td>-0.194575</td>\n",
       "      <td>-0.191620</td>\n",
       "      <td>-0.024852</td>\n",
       "      <td>-0.269705</td>\n",
       "      <td>0.112572</td>\n",
       "      <td>0.940564</td>\n",
       "      <td>0.934862</td>\n",
       "      <td>0.938286</td>\n",
       "      <td>0.498571</td>\n",
       "      <td>0.499558</td>\n",
       "      <td>0.502453</td>\n",
       "      <td>0.491263</td>\n",
       "      <td>0.360620</td>\n",
       "      <td>0.354866</td>\n",
       "      <td>0.048121</td>\n",
       "      <td>0.281973</td>\n",
       "      <td>0.282050</td>\n",
       "      <td>-0.821618</td>\n",
       "      <td>-0.830842</td>\n",
       "      <td>-0.826807</td>\n",
       "      <td>0.449196</td>\n",
       "      <td>0.449741</td>\n",
       "      <td>0.450099</td>\n",
       "      <td>0.447269</td>\n",
       "      <td>0.102862</td>\n",
       "      <td>0.083699</td>\n",
       "      <td>0.057529</td>\n",
       "      <td>-0.798319</td>\n",
       "      <td>0.051676</td>\n",
       "      <td>-0.866497</td>\n",
       "      <td>-0.864090</td>\n",
       "      <td>-0.865810</td>\n",
       "      <td>-1.271984</td>\n",
       "      <td>-1.272995</td>\n",
       "      <td>-1.277537</td>\n",
       "      <td>-1.263811</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>-0.553448</td>\n",
       "      <td>-0.023915</td>\n",
       "      <td>-0.394632</td>\n",
       "      <td>-0.494992</td>\n",
       "      <td>-0.267474</td>\n",
       "      <td>-0.665770</td>\n",
       "      <td>0.799502</td>\n",
       "      <td>-0.692162</td>\n",
       "      <td>-0.738833</td>\n",
       "      <td>-0.528406</td>\n",
       "      <td>-0.718486</td>\n",
       "      <td>-0.066969</td>\n",
       "      <td>-0.665770</td>\n",
       "      <td>0.799502</td>\n",
       "      <td>-0.502897</td>\n",
       "      <td>-1.008525</td>\n",
       "      <td>-1.011737</td>\n",
       "      <td>-1.020391</td>\n",
       "      <td>-0.987214</td>\n",
       "      <td>-0.081395</td>\n",
       "      <td>-0.116338</td>\n",
       "      <td>-0.113672</td>\n",
       "      <td>-0.299994</td>\n",
       "      <td>0.064751</td>\n",
       "      <td>-1.020391</td>\n",
       "      <td>-0.987214</td>\n",
       "      <td>-1.004119</td>\n",
       "      <td>-0.282622</td>\n",
       "      <td>-0.257596</td>\n",
       "      <td>-0.361545</td>\n",
       "      <td>-0.097638</td>\n",
       "      <td>-0.382266</td>\n",
       "      <td>-0.373975</td>\n",
       "      <td>-0.622608</td>\n",
       "      <td>-0.361711</td>\n",
       "      <td>0.012413</td>\n",
       "      <td>-0.361545</td>\n",
       "      <td>-0.097638</td>\n",
       "      <td>-0.349948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2      ...          165       166       167\n",
       "0 -1.080161 -1.079898 -1.089366    ...     0.143058  0.063600  0.139838\n",
       "1 -1.371767 -1.371667 -1.381118    ...    -0.075991 -0.166719 -0.081564\n",
       "2 -0.720492 -0.720416 -0.726728    ...     0.090946  0.030849  0.088373\n",
       "3 -1.343418 -1.343338 -1.352650    ...     0.034807 -0.381534  0.012270\n",
       "4 -1.273604 -1.273001 -1.276691    ...    -0.361545 -0.097638 -0.349948\n",
       "\n",
       "[5 rows x 168 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(train_df))\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(test_df))\n",
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Label Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id  group_id  surface\n",
       "0          0        13        2\n",
       "1          1        31        1\n",
       "2          2        20        1\n",
       "3          3        31        1\n",
       "4          4        22        6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "target['surface'] = le.fit_transform(target['surface'])\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X_train_scaled\n",
    "test = X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.zeros((test.shape[0],9))\n",
    "measured = np.zeros((data.shape[0]))\n",
    "score = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SUFFLE + BOOTSTRAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/jiweiliu/lgb-2-leaves-augment#500381\n",
    "def shuffle_col_vals(x1):\n",
    "    rand_x = np.array([np.random.choice(x1.shape[0], size=x1.shape[0], replace=False) for i in range(x1.shape[1])]).T\n",
    "    grid = np.indices(x1.shape)\n",
    "    rand_y = grid[1]\n",
    "    return x1[(rand_x, rand_y)]\n",
    "\n",
    "def augment(x,y,t=2):\n",
    "    xs,xn = [],[]\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        x1 = shuffle_col_vals(x1)\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        x1 = shuffle_col_vals(x1)\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs); xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0]);yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn]); y = np.concatenate([y,ys,yn])\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 50.7min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 84.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 131.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1500 out of 1500 | elapsed: 160.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.897375 using {'min_data_in_leaf': 39, 'max_depth': 15, 'learning_rate': 0.07642417764245664, 'lambda_l1': 0.002513522513178712, 'feature_fraction': 0.5649369933980897, 'bagging_fraction': 0.5130894826934904}\n",
      "0.762205 (0.012460) with: {'min_data_in_leaf': 229, 'max_depth': 8, 'learning_rate': 0.013454328645194292, 'lambda_l1': 0.5743965126768239, 'feature_fraction': 0.635260910304736, 'bagging_fraction': 0.9380905528605239}\n",
      "0.835958 (0.009822) with: {'min_data_in_leaf': 350, 'max_depth': 15, 'learning_rate': 0.055470557237504874, 'lambda_l1': 0.3719187133676075, 'feature_fraction': 0.654983496819531, 'bagging_fraction': 0.379705010170145}\n",
      "0.827034 (0.014819) with: {'min_data_in_leaf': 452, 'max_depth': 6, 'learning_rate': 0.07900607532486592, 'lambda_l1': 0.5795473889441491, 'feature_fraction': 0.39314961511831553, 'bagging_fraction': 0.6554462045441563}\n",
      "0.844357 (0.008463) with: {'min_data_in_leaf': 358, 'max_depth': 24, 'learning_rate': 0.07277215741400064, 'lambda_l1': 0.36029345237894495, 'feature_fraction': 0.5904195866928716, 'bagging_fraction': 0.8958131682182607}\n",
      "0.857218 (0.010999) with: {'min_data_in_leaf': 314, 'max_depth': 11, 'learning_rate': 0.08929613283267669, 'lambda_l1': 0.6783354830490685, 'feature_fraction': 0.5442673947768529, 'bagging_fraction': 0.8963129802457994}\n",
      "0.880052 (0.014004) with: {'min_data_in_leaf': 63, 'max_depth': 8, 'learning_rate': 0.050057432807981334, 'lambda_l1': 0.7092379501829046, 'feature_fraction': 0.5456415642372383, 'bagging_fraction': 0.8365926208807126}\n",
      "0.883202 (0.013155) with: {'min_data_in_leaf': 86, 'max_depth': 6, 'learning_rate': 0.05929308904424368, 'lambda_l1': 0.3716244387000136, 'feature_fraction': 0.3658952971465034, 'bagging_fraction': 0.9417327193045877}\n",
      "0.872966 (0.012004) with: {'min_data_in_leaf': 180, 'max_depth': 20, 'learning_rate': 0.07900607532486592, 'lambda_l1': 0.8497457437298098, 'feature_fraction': 0.8460950802136225, 'bagging_fraction': 0.379705010170145}\n",
      "0.878740 (0.010823) with: {'min_data_in_leaf': 95, 'max_depth': 18, 'learning_rate': 0.09015791681866688, 'lambda_l1': 0.7838789207037316, 'feature_fraction': 0.8957153985016165, 'bagging_fraction': 0.7448893139261881}\n",
      "0.807349 (0.013340) with: {'min_data_in_leaf': 334, 'max_depth': 15, 'learning_rate': 0.030272023334673465, 'lambda_l1': 0.0229168725707376, 'feature_fraction': 0.5969838483809656, 'bagging_fraction': 0.8112232384116959}\n",
      "0.850394 (0.010305) with: {'min_data_in_leaf': 166, 'max_depth': 16, 'learning_rate': 0.02578851154951003, 'lambda_l1': 0.7818279911269091, 'feature_fraction': 0.5609571579118078, 'bagging_fraction': 0.5408959038385701}\n",
      "0.861680 (0.011997) with: {'min_data_in_leaf': 182, 'max_depth': 20, 'learning_rate': 0.0377772411048523, 'lambda_l1': 0.2586558749598573, 'feature_fraction': 0.5641027998858984, 'bagging_fraction': 0.8513149074233138}\n",
      "0.832808 (0.016552) with: {'min_data_in_leaf': 444, 'max_depth': 16, 'learning_rate': 0.09391968177530917, 'lambda_l1': 0.36563369104357557, 'feature_fraction': 0.5799558657673334, 'bagging_fraction': 0.9738282828691349}\n",
      "0.890814 (0.011845) with: {'min_data_in_leaf': 39, 'max_depth': 18, 'learning_rate': 0.06388548639690404, 'lambda_l1': 0.2698246642448642, 'feature_fraction': 0.5099201858168457, 'bagging_fraction': 0.5130894826934904}\n",
      "0.616273 (0.017489) with: {'min_data_in_leaf': 404, 'max_depth': 20, 'learning_rate': 0.005640434649582631, 'lambda_l1': 0.9118242205809006, 'feature_fraction': 0.281920071319123, 'bagging_fraction': 0.4968805090171967}\n",
      "0.861417 (0.011282) with: {'min_data_in_leaf': 265, 'max_depth': 20, 'learning_rate': 0.07099840729098683, 'lambda_l1': 0.11390729907715968, 'feature_fraction': 0.6412408193430215, 'bagging_fraction': 0.25846794883628976}\n",
      "0.875066 (0.011755) with: {'min_data_in_leaf': 78, 'max_depth': 22, 'learning_rate': 0.0339343234712795, 'lambda_l1': 0.9741394741652668, 'feature_fraction': 0.5799558657673334, 'bagging_fraction': 0.945885930099219}\n",
      "0.872441 (0.013493) with: {'min_data_in_leaf': 215, 'max_depth': 10, 'learning_rate': 0.08422271296560567, 'lambda_l1': 0.5542296387939777, 'feature_fraction': 0.30974551145716417, 'bagging_fraction': 0.37209448530230227}\n",
      "0.824672 (0.013519) with: {'min_data_in_leaf': 358, 'max_depth': 15, 'learning_rate': 0.045252763269019405, 'lambda_l1': 0.7823027194464269, 'feature_fraction': 0.7336787831311864, 'bagging_fraction': 0.742168386368243}\n",
      "0.851444 (0.008605) with: {'min_data_in_leaf': 360, 'max_depth': 21, 'learning_rate': 0.09015791681866688, 'lambda_l1': 0.04240143550427078, 'feature_fraction': 0.565231679676507, 'bagging_fraction': 0.742168386368243}\n",
      "0.867454 (0.011381) with: {'min_data_in_leaf': 215, 'max_depth': 15, 'learning_rate': 0.05702857015428802, 'lambda_l1': 0.27942308816648775, 'feature_fraction': 0.5785248419232365, 'bagging_fraction': 0.6689985549776225}\n",
      "0.838845 (0.013634) with: {'min_data_in_leaf': 315, 'max_depth': 13, 'learning_rate': 0.05193025728426503, 'lambda_l1': 0.7185708493539409, 'feature_fraction': 0.4465587851298521, 'bagging_fraction': 0.7294283574127564}\n",
      "0.836483 (0.011217) with: {'min_data_in_leaf': 335, 'max_depth': 8, 'learning_rate': 0.05349035900089145, 'lambda_l1': 0.48777893105001313, 'feature_fraction': 0.7600505387536944, 'bagging_fraction': 0.38339233561184966}\n",
      "0.642520 (0.019311) with: {'min_data_in_leaf': 452, 'max_depth': 15, 'learning_rate': 0.009378159977376453, 'lambda_l1': 0.9352065412738418, 'feature_fraction': 0.3883151880566519, 'bagging_fraction': 0.3077214751506768}\n",
      "0.890551 (0.011752) with: {'min_data_in_leaf': 39, 'max_depth': 15, 'learning_rate': 0.03291133109983079, 'lambda_l1': 0.07158928791812136, 'feature_fraction': 0.7646600384009693, 'bagging_fraction': 0.27871779271416575}\n",
      "0.860367 (0.013739) with: {'min_data_in_leaf': 10, 'max_depth': 14, 'learning_rate': 0.008247096193880924, 'lambda_l1': 0.5795473889441491, 'feature_fraction': 0.7226462560789778, 'bagging_fraction': 0.4968805090171967}\n",
      "0.864042 (0.014098) with: {'min_data_in_leaf': 267, 'max_depth': 18, 'learning_rate': 0.08438133513274937, 'lambda_l1': 0.2698246642448642, 'feature_fraction': 0.3149140591340587, 'bagging_fraction': 0.4336778841636613}\n",
      "0.882415 (0.008833) with: {'min_data_in_leaf': 94, 'max_depth': 16, 'learning_rate': 0.09657260984210976, 'lambda_l1': 0.474254957273592, 'feature_fraction': 0.9052385146707156, 'bagging_fraction': 0.3302284216934376}\n",
      "0.810761 (0.012078) with: {'min_data_in_leaf': 485, 'max_depth': 23, 'learning_rate': 0.06289115956502811, 'lambda_l1': 0.12111758030678055, 'feature_fraction': 0.7447334193718799, 'bagging_fraction': 0.34910546997627084}\n",
      "0.836745 (0.012113) with: {'min_data_in_leaf': 227, 'max_depth': 6, 'learning_rate': 0.03230365398332675, 'lambda_l1': 0.33459079555609617, 'feature_fraction': 0.7572436586732458, 'bagging_fraction': 0.734074075586154}\n",
      "0.857743 (0.010330) with: {'min_data_in_leaf': 314, 'max_depth': 14, 'learning_rate': 0.09690037316988012, 'lambda_l1': 0.4995878322102484, 'feature_fraction': 0.36543150365880905, 'bagging_fraction': 0.25846794883628976}\n",
      "0.869816 (0.012966) with: {'min_data_in_leaf': 127, 'max_depth': 19, 'learning_rate': 0.030272023334673465, 'lambda_l1': 0.36563369104357557, 'feature_fraction': 0.624311022570671, 'bagging_fraction': 0.7745208257132506}\n",
      "0.892913 (0.013205) with: {'min_data_in_leaf': 39, 'max_depth': 20, 'learning_rate': 0.086161762527122, 'lambda_l1': 0.1058149777678492, 'feature_fraction': 0.45652194155443326, 'bagging_fraction': 0.3302284216934376}\n",
      "0.798425 (0.011653) with: {'min_data_in_leaf': 309, 'max_depth': 22, 'learning_rate': 0.024954384929868505, 'lambda_l1': 0.2840345436239562, 'feature_fraction': 0.286399698297305, 'bagging_fraction': 0.7184856339205163}\n",
      "0.878740 (0.011204) with: {'min_data_in_leaf': 63, 'max_depth': 8, 'learning_rate': 0.03947135805337951, 'lambda_l1': 0.7064718465056312, 'feature_fraction': 0.7600505387536944, 'bagging_fraction': 0.3288677187424649}\n",
      "0.879790 (0.011430) with: {'min_data_in_leaf': 100, 'max_depth': 13, 'learning_rate': 0.09278280599748451, 'lambda_l1': 0.44364921142671776, 'feature_fraction': 0.8157350971483801, 'bagging_fraction': 0.9310017353861981}\n",
      "0.879003 (0.013488) with: {'min_data_in_leaf': 98, 'max_depth': 6, 'learning_rate': 0.09657260984210976, 'lambda_l1': 0.5743965126768239, 'feature_fraction': 0.875323706202931, 'bagging_fraction': 0.6738601112210277}\n",
      "0.879790 (0.011315) with: {'min_data_in_leaf': 63, 'max_depth': 8, 'learning_rate': 0.030272023334673465, 'lambda_l1': 0.4812592325911569, 'feature_fraction': 0.8895086996955018, 'bagging_fraction': 0.8112232384116959}\n",
      "0.853018 (0.010432) with: {'min_data_in_leaf': 273, 'max_depth': 16, 'learning_rate': 0.05193025728426503, 'lambda_l1': 0.002513522513178712, 'feature_fraction': 0.32555869865238724, 'bagging_fraction': 0.8161691192505147}\n",
      "0.853806 (0.010292) with: {'min_data_in_leaf': 273, 'max_depth': 10, 'learning_rate': 0.05842234797404635, 'lambda_l1': 0.7838789207037316, 'feature_fraction': 0.31895953602368793, 'bagging_fraction': 0.8887038704340252}\n",
      "0.879265 (0.013182) with: {'min_data_in_leaf': 46, 'max_depth': 14, 'learning_rate': 0.024954384929868505, 'lambda_l1': 0.6170347546607704, 'feature_fraction': 0.7336787831311864, 'bagging_fraction': 0.8537518674305191}\n",
      "0.869816 (0.013743) with: {'min_data_in_leaf': 227, 'max_depth': 23, 'learning_rate': 0.08422271296560567, 'lambda_l1': 0.37112241607033514, 'feature_fraction': 0.5985626632600937, 'bagging_fraction': 0.32322812469430157}\n",
      "0.843307 (0.012018) with: {'min_data_in_leaf': 314, 'max_depth': 16, 'learning_rate': 0.05349035900089145, 'lambda_l1': 0.4617051468784279, 'feature_fraction': 0.281920071319123, 'bagging_fraction': 0.7911635060829941}\n",
      "0.830446 (0.014734) with: {'min_data_in_leaf': 451, 'max_depth': 21, 'learning_rate': 0.09015791681866688, 'lambda_l1': 0.2698246642448642, 'feature_fraction': 0.7600505387536944, 'bagging_fraction': 0.6406590331277203}\n",
      "0.860367 (0.009524) with: {'min_data_in_leaf': 182, 'max_depth': 8, 'learning_rate': 0.03734756670129417, 'lambda_l1': 0.7720304419981351, 'feature_fraction': 0.3418930712499858, 'bagging_fraction': 0.6554462045441563}\n",
      "0.878215 (0.016181) with: {'min_data_in_leaf': 193, 'max_depth': 23, 'learning_rate': 0.09870127105888815, 'lambda_l1': 0.28451503882070794, 'feature_fraction': 0.9908423730367056, 'bagging_fraction': 0.9200715261582939}\n",
      "0.855118 (0.014049) with: {'min_data_in_leaf': 323, 'max_depth': 15, 'learning_rate': 0.08929613283267669, 'lambda_l1': 0.8269453104529011, 'feature_fraction': 0.46351951866819574, 'bagging_fraction': 0.5408959038385701}\n",
      "0.884514 (0.013381) with: {'min_data_in_leaf': 76, 'max_depth': 8, 'learning_rate': 0.08261805826337704, 'lambda_l1': 0.4054817579814104, 'feature_fraction': 0.8097520112238722, 'bagging_fraction': 0.5035680180174651}\n",
      "0.859843 (0.011394) with: {'min_data_in_leaf': 265, 'max_depth': 10, 'learning_rate': 0.07642417764245664, 'lambda_l1': 0.4617051468784279, 'feature_fraction': 0.8553741661059728, 'bagging_fraction': 0.8551916590457058}\n",
      "0.825459 (0.003908) with: {'min_data_in_leaf': 108, 'max_depth': 15, 'learning_rate': 0.013912138308510836, 'lambda_l1': 0.5686982338916955, 'feature_fraction': 0.875323706202931, 'bagging_fraction': 0.3418245002473473}\n",
      "0.869816 (0.010359) with: {'min_data_in_leaf': 105, 'max_depth': 18, 'learning_rate': 0.02510153212888405, 'lambda_l1': 0.12111758030678055, 'feature_fraction': 0.483418773988896, 'bagging_fraction': 0.5035680180174651}\n",
      "0.872703 (0.012222) with: {'min_data_in_leaf': 174, 'max_depth': 21, 'learning_rate': 0.07753658823149953, 'lambda_l1': 0.9299752272368015, 'feature_fraction': 0.5641027998858984, 'bagging_fraction': 0.8551916590457058}\n",
      "0.880315 (0.010721) with: {'min_data_in_leaf': 35, 'max_depth': 22, 'learning_rate': 0.0339343234712795, 'lambda_l1': 0.7818279911269091, 'feature_fraction': 0.875323706202931, 'bagging_fraction': 0.8161691192505147}\n",
      "0.801050 (0.015615) with: {'min_data_in_leaf': 323, 'max_depth': 14, 'learning_rate': 0.027773614178748875, 'lambda_l1': 0.7676138603555922, 'feature_fraction': 0.5904195866928716, 'bagging_fraction': 0.5773093966214555}\n",
      "0.884777 (0.015247) with: {'min_data_in_leaf': 76, 'max_depth': 9, 'learning_rate': 0.08261805826337704, 'lambda_l1': 0.30495535472261937, 'feature_fraction': 0.8553741661059728, 'bagging_fraction': 0.8551916590457058}\n",
      "0.880840 (0.010693) with: {'min_data_in_leaf': 107, 'max_depth': 15, 'learning_rate': 0.08261805826337704, 'lambda_l1': 0.7092379501829046, 'feature_fraction': 0.36123770532301147, 'bagging_fraction': 0.5130894826934904}\n",
      "0.819160 (0.012946) with: {'min_data_in_leaf': 60, 'max_depth': 16, 'learning_rate': 0.008247096193880924, 'lambda_l1': 0.5743965126768239, 'feature_fraction': 0.7226462560789778, 'bagging_fraction': 0.8024375602992573}\n",
      "0.880052 (0.011828) with: {'min_data_in_leaf': 98, 'max_depth': 11, 'learning_rate': 0.09657260984210976, 'lambda_l1': 0.5743965126768239, 'feature_fraction': 0.5904195866928716, 'bagging_fraction': 0.5130894826934904}\n",
      "0.789501 (0.009417) with: {'min_data_in_leaf': 444, 'max_depth': 14, 'learning_rate': 0.03621606577038674, 'lambda_l1': 0.1058149777678492, 'feature_fraction': 0.7226462560789778, 'bagging_fraction': 0.8161691192505147}\n",
      "0.760105 (0.015667) with: {'min_data_in_leaf': 452, 'max_depth': 19, 'learning_rate': 0.02578851154951003, 'lambda_l1': 0.30495535472261937, 'feature_fraction': 0.7295314719844266, 'bagging_fraction': 0.880304318067094}\n",
      "0.841207 (0.008748) with: {'min_data_in_leaf': 335, 'max_depth': 15, 'learning_rate': 0.05842234797404635, 'lambda_l1': 0.569237934867056, 'feature_fraction': 0.41407765876503005, 'bagging_fraction': 0.2551709987611082}\n",
      "0.869291 (0.011175) with: {'min_data_in_leaf': 174, 'max_depth': 14, 'learning_rate': 0.05193025728426503, 'lambda_l1': 0.7268509968724453, 'feature_fraction': 0.44317463850325417, 'bagging_fraction': 0.39637642980329024}\n",
      "0.878740 (0.010114) with: {'min_data_in_leaf': 146, 'max_depth': 7, 'learning_rate': 0.09391968177530917, 'lambda_l1': 0.4680790035784811, 'feature_fraction': 0.4186226386680377, 'bagging_fraction': 0.43278237886373955}\n",
      "0.820472 (0.010866) with: {'min_data_in_leaf': 222, 'max_depth': 10, 'learning_rate': 0.023345956962948167, 'lambda_l1': 0.4812592325911569, 'feature_fraction': 0.36543150365880905, 'bagging_fraction': 0.7958742662602173}\n",
      "0.873491 (0.013030) with: {'min_data_in_leaf': 25, 'max_depth': 6, 'learning_rate': 0.02578851154951003, 'lambda_l1': 0.3719187133676075, 'feature_fraction': 0.8895086996955018, 'bagging_fraction': 0.7294283574127564}\n",
      "0.877953 (0.009228) with: {'min_data_in_leaf': 172, 'max_depth': 15, 'learning_rate': 0.05929308904424368, 'lambda_l1': 0.4495089235411983, 'feature_fraction': 0.281920071319123, 'bagging_fraction': 0.8551916590457058}\n",
      "0.821785 (0.013570) with: {'min_data_in_leaf': 63, 'max_depth': 8, 'learning_rate': 0.009378159977376453, 'lambda_l1': 0.7064718465056312, 'feature_fraction': 0.9440920268461748, 'bagging_fraction': 0.7745208257132506}\n",
      "0.882415 (0.011619) with: {'min_data_in_leaf': 43, 'max_depth': 13, 'learning_rate': 0.037020389351308185, 'lambda_l1': 0.42679807656157, 'feature_fraction': 0.6472616018676403, 'bagging_fraction': 0.47754937346312687}\n",
      "0.854068 (0.013701) with: {'min_data_in_leaf': 358, 'max_depth': 23, 'learning_rate': 0.09740496522804008, 'lambda_l1': 0.09406375049907645, 'feature_fraction': 0.39314961511831553, 'bagging_fraction': 0.9738282828691349}\n",
      "0.879003 (0.014944) with: {'min_data_in_leaf': 174, 'max_depth': 8, 'learning_rate': 0.09391968177530917, 'lambda_l1': 0.36563369104357557, 'feature_fraction': 0.7573720317174075, 'bagging_fraction': 0.39637642980329024}\n",
      "0.866404 (0.013052) with: {'min_data_in_leaf': 268, 'max_depth': 21, 'learning_rate': 0.09571883239135656, 'lambda_l1': 0.3366165618496434, 'feature_fraction': 0.64900601925637, 'bagging_fraction': 0.945885930099219}\n",
      "0.829659 (0.013638) with: {'min_data_in_leaf': 315, 'max_depth': 7, 'learning_rate': 0.038862739908887584, 'lambda_l1': 0.4680790035784811, 'feature_fraction': 0.9927102934372364, 'bagging_fraction': 0.8551916590457058}\n",
      "0.858268 (0.007934) with: {'min_data_in_leaf': 267, 'max_depth': 13, 'learning_rate': 0.08118751445096514, 'lambda_l1': 0.712443534911368, 'feature_fraction': 0.8419435194614723, 'bagging_fraction': 0.6406590331277203}\n",
      "0.894226 (0.012729) with: {'min_data_in_leaf': 69, 'max_depth': 10, 'learning_rate': 0.09657260984210976, 'lambda_l1': 0.03647146803495993, 'feature_fraction': 0.3658952971465034, 'bagging_fraction': 0.9004617349778057}\n",
      "0.865354 (0.013214) with: {'min_data_in_leaf': 215, 'max_depth': 6, 'learning_rate': 0.06772179392405428, 'lambda_l1': 0.48000990586859427, 'feature_fraction': 0.9088838105716656, 'bagging_fraction': 0.3939980126973871}\n",
      "0.877165 (0.014269) with: {'min_data_in_leaf': 193, 'max_depth': 24, 'learning_rate': 0.08438133513274937, 'lambda_l1': 0.3366165618496434, 'feature_fraction': 0.7573720317174075, 'bagging_fraction': 0.7720398497026818}\n",
      "0.881627 (0.012804) with: {'min_data_in_leaf': 94, 'max_depth': 6, 'learning_rate': 0.07543608285431669, 'lambda_l1': 0.5146331823407098, 'feature_fraction': 0.7226462560789778, 'bagging_fraction': 0.5727781337792712}\n",
      "0.828871 (0.011259) with: {'min_data_in_leaf': 311, 'max_depth': 6, 'learning_rate': 0.0406280445523634, 'lambda_l1': 0.7092379501829046, 'feature_fraction': 0.45652194155443326, 'bagging_fraction': 0.9004617349778057}\n",
      "0.503937 (0.018549) with: {'min_data_in_leaf': 227, 'max_depth': 23, 'learning_rate': 0.001020114229481105, 'lambda_l1': 0.768540095608294, 'feature_fraction': 0.6412408193430215, 'bagging_fraction': 0.9004617349778057}\n",
      "0.833596 (0.009687) with: {'min_data_in_leaf': 225, 'max_depth': 21, 'learning_rate': 0.030272023334673465, 'lambda_l1': 0.8014377513314559, 'feature_fraction': 0.3883151880566519, 'bagging_fraction': 0.4275701070310328}\n",
      "0.853543 (0.010653) with: {'min_data_in_leaf': 167, 'max_depth': 20, 'learning_rate': 0.02578851154951003, 'lambda_l1': 0.09406375049907645, 'feature_fraction': 0.7063936404422937, 'bagging_fraction': 0.9417327193045877}\n",
      "0.827559 (0.008190) with: {'min_data_in_leaf': 499, 'max_depth': 10, 'learning_rate': 0.09870127105888815, 'lambda_l1': 0.06769800845082086, 'feature_fraction': 0.6146175380529777, 'bagging_fraction': 0.8887038704340252}\n",
      "0.853543 (0.008597) with: {'min_data_in_leaf': 265, 'max_depth': 24, 'learning_rate': 0.06279742999723735, 'lambda_l1': 0.9118242205809006, 'feature_fraction': 0.7405727776842674, 'bagging_fraction': 0.8365926208807126}\n",
      "0.690551 (0.007710) with: {'min_data_in_leaf': 404, 'max_depth': 9, 'learning_rate': 0.013069989674861475, 'lambda_l1': 0.8497457437298098, 'feature_fraction': 0.688558420117676, 'bagging_fraction': 0.8161691192505147}\n",
      "0.807874 (0.014882) with: {'min_data_in_leaf': 60, 'max_depth': 19, 'learning_rate': 0.005640434649582631, 'lambda_l1': 0.44364921142671776, 'feature_fraction': 0.3149140591340587, 'bagging_fraction': 0.3302284216934376}\n",
      "0.872178 (0.010676) with: {'min_data_in_leaf': 80, 'max_depth': 8, 'learning_rate': 0.030272023334673465, 'lambda_l1': 0.9299752272368015, 'feature_fraction': 0.6146175380529777, 'bagging_fraction': 0.8112232384116959}\n",
      "0.885564 (0.011094) with: {'min_data_in_leaf': 94, 'max_depth': 13, 'learning_rate': 0.07069005269842409, 'lambda_l1': 0.09406375049907645, 'feature_fraction': 0.5969838483809656, 'bagging_fraction': 0.474008781815512}\n",
      "0.823622 (0.012617) with: {'min_data_in_leaf': 487, 'max_depth': 16, 'learning_rate': 0.08371533590361077, 'lambda_l1': 0.44364921142671776, 'feature_fraction': 0.6472616018676403, 'bagging_fraction': 0.4502890231195096}\n",
      "0.567454 (0.020297) with: {'min_data_in_leaf': 111, 'max_depth': 6, 'learning_rate': 0.001020114229481105, 'lambda_l1': 0.09406375049907645, 'feature_fraction': 0.9440920268461748, 'bagging_fraction': 0.9292989475415088}\n",
      "0.678215 (0.012362) with: {'min_data_in_leaf': 350, 'max_depth': 21, 'learning_rate': 0.009378159977376453, 'lambda_l1': 0.013254460525070733, 'feature_fraction': 0.47705075075993436, 'bagging_fraction': 0.9310017353861981}\n",
      "0.833333 (0.011277) with: {'min_data_in_leaf': 78, 'max_depth': 14, 'learning_rate': 0.011476906105266986, 'lambda_l1': 0.539374732480692, 'feature_fraction': 0.44583329686726947, 'bagging_fraction': 0.9520115309186076}\n",
      "0.866404 (0.010871) with: {'min_data_in_leaf': 55, 'max_depth': 8, 'learning_rate': 0.01974228954292596, 'lambda_l1': 0.9258939609762522, 'feature_fraction': 0.5148130977353862, 'bagging_fraction': 0.5018624408577049}\n",
      "0.854593 (0.012854) with: {'min_data_in_leaf': 274, 'max_depth': 9, 'learning_rate': 0.07069005269842409, 'lambda_l1': 0.8820111581615196, 'feature_fraction': 0.565231679676507, 'bagging_fraction': 0.9004617349778057}\n",
      "0.830971 (0.008482) with: {'min_data_in_leaf': 396, 'max_depth': 15, 'learning_rate': 0.06279742999723735, 'lambda_l1': 0.539374732480692, 'feature_fraction': 0.3149140591340587, 'bagging_fraction': 0.868506811716675}\n",
      "0.830971 (0.010363) with: {'min_data_in_leaf': 146, 'max_depth': 9, 'learning_rate': 0.017929787694683244, 'lambda_l1': 0.7185708493539409, 'feature_fraction': 0.5799558657673334, 'bagging_fraction': 0.3077214751506768}\n",
      "0.849606 (0.010207) with: {'min_data_in_leaf': 266, 'max_depth': 16, 'learning_rate': 0.05088177687700322, 'lambda_l1': 0.48000990586859427, 'feature_fraction': 0.9052385146707156, 'bagging_fraction': 0.9738282828691349}\n",
      "0.840682 (0.012208) with: {'min_data_in_leaf': 357, 'max_depth': 23, 'learning_rate': 0.07642417764245664, 'lambda_l1': 0.9118242205809006, 'feature_fraction': 0.5785248419232365, 'bagging_fraction': 0.7067363239675439}\n",
      "0.786614 (0.009502) with: {'min_data_in_leaf': 357, 'max_depth': 11, 'learning_rate': 0.02578851154951003, 'lambda_l1': 0.6766385237720431, 'feature_fraction': 0.3524323694255008, 'bagging_fraction': 0.9557101498470986}\n",
      "0.734121 (0.008044) with: {'min_data_in_leaf': 420, 'max_depth': 7, 'learning_rate': 0.018774236883284737, 'lambda_l1': 0.474254957273592, 'feature_fraction': 0.9927102934372364, 'bagging_fraction': 0.9417327193045877}\n",
      "0.868504 (0.013626) with: {'min_data_in_leaf': 215, 'max_depth': 8, 'learning_rate': 0.06388548639690404, 'lambda_l1': 0.06769800845082086, 'feature_fraction': 0.9927102934372364, 'bagging_fraction': 0.9951392141692306}\n",
      "0.869816 (0.013509) with: {'min_data_in_leaf': 215, 'max_depth': 22, 'learning_rate': 0.07642417764245664, 'lambda_l1': 0.5542296387939777, 'feature_fraction': 0.565231679676507, 'bagging_fraction': 0.9738282828691349}\n",
      "0.828609 (0.010931) with: {'min_data_in_leaf': 493, 'max_depth': 6, 'learning_rate': 0.08929613283267669, 'lambda_l1': 0.2586558749598573, 'feature_fraction': 0.32555869865238724, 'bagging_fraction': 0.932705291267405}\n",
      "0.850656 (0.009059) with: {'min_data_in_leaf': 103, 'max_depth': 15, 'learning_rate': 0.01832045737332351, 'lambda_l1': 0.17394444093745598, 'feature_fraction': 0.4573511343558394, 'bagging_fraction': 0.7294283574127564}\n",
      "0.789764 (0.012108) with: {'min_data_in_leaf': 451, 'max_depth': 15, 'learning_rate': 0.038938302509715805, 'lambda_l1': 0.7381059992184543, 'feature_fraction': 0.7447334193718799, 'bagging_fraction': 0.8161691192505147}\n",
      "0.864567 (0.011147) with: {'min_data_in_leaf': 172, 'max_depth': 7, 'learning_rate': 0.0406280445523634, 'lambda_l1': 0.5741268985393458, 'feature_fraction': 0.30974551145716417, 'bagging_fraction': 0.932705291267405}\n",
      "0.816798 (0.012897) with: {'min_data_in_leaf': 452, 'max_depth': 8, 'learning_rate': 0.06289115956502811, 'lambda_l1': 0.9258939609762522, 'feature_fraction': 0.5969838483809656, 'bagging_fraction': 0.474008781815512}\n",
      "0.690551 (0.011013) with: {'min_data_in_leaf': 105, 'max_depth': 23, 'learning_rate': 0.002459362126359497, 'lambda_l1': 0.18615782354161348, 'feature_fraction': 0.7572436586732458, 'bagging_fraction': 0.932705291267405}\n",
      "0.835171 (0.009442) with: {'min_data_in_leaf': 199, 'max_depth': 7, 'learning_rate': 0.026611196581581426, 'lambda_l1': 0.7823027194464269, 'feature_fraction': 0.64900601925637, 'bagging_fraction': 0.474008781815512}\n",
      "0.856693 (0.005708) with: {'min_data_in_leaf': 335, 'max_depth': 14, 'learning_rate': 0.08089758967843194, 'lambda_l1': 0.1058149777678492, 'feature_fraction': 0.36123770532301147, 'bagging_fraction': 0.7067363239675439}\n",
      "0.845407 (0.012098) with: {'min_data_in_leaf': 265, 'max_depth': 24, 'learning_rate': 0.04544626322739714, 'lambda_l1': 0.4923777038258458, 'feature_fraction': 0.44317463850325417, 'bagging_fraction': 0.4662078680075106}\n",
      "0.851181 (0.009725) with: {'min_data_in_leaf': 86, 'max_depth': 6, 'learning_rate': 0.0227158373311089, 'lambda_l1': 0.47874510710140716, 'feature_fraction': 0.6083293190678971, 'bagging_fraction': 0.8049894149691099}\n",
      "0.827822 (0.012220) with: {'min_data_in_leaf': 487, 'max_depth': 18, 'learning_rate': 0.09278280599748451, 'lambda_l1': 0.013254460525070733, 'feature_fraction': 0.5985626632600937, 'bagging_fraction': 0.8024375602992573}\n",
      "0.829396 (0.011193) with: {'min_data_in_leaf': 404, 'max_depth': 10, 'learning_rate': 0.06289115956502811, 'lambda_l1': 0.4617051468784279, 'feature_fraction': 0.7063936404422937, 'bagging_fraction': 0.6738601112210277}\n",
      "0.879790 (0.010235) with: {'min_data_in_leaf': 80, 'max_depth': 19, 'learning_rate': 0.0406280445523634, 'lambda_l1': 0.5069748646478869, 'feature_fraction': 0.828435138016004, 'bagging_fraction': 0.43278237886373955}\n",
      "0.874541 (0.010798) with: {'min_data_in_leaf': 105, 'max_depth': 6, 'learning_rate': 0.051962895756180065, 'lambda_l1': 0.8269453104529011, 'feature_fraction': 0.4465587851298521, 'bagging_fraction': 0.39637642980329024}\n",
      "0.887139 (0.013159) with: {'min_data_in_leaf': 105, 'max_depth': 6, 'learning_rate': 0.07277215741400064, 'lambda_l1': 0.05123431330436523, 'feature_fraction': 0.4465587851298521, 'bagging_fraction': 0.34910546997627084}\n",
      "0.724934 (0.011793) with: {'min_data_in_leaf': 466, 'max_depth': 10, 'learning_rate': 0.01850410129981584, 'lambda_l1': 0.03735765092636889, 'feature_fraction': 0.5456415642372383, 'bagging_fraction': 0.485719403654563}\n",
      "0.862730 (0.008887) with: {'min_data_in_leaf': 105, 'max_depth': 10, 'learning_rate': 0.024954384929868505, 'lambda_l1': 0.5542296387939777, 'feature_fraction': 0.4465587851298521, 'bagging_fraction': 0.8049894149691099}\n",
      "0.867979 (0.013254) with: {'min_data_in_leaf': 249, 'max_depth': 11, 'learning_rate': 0.08261805826337704, 'lambda_l1': 0.30495535472261937, 'feature_fraction': 0.26918461598142596, 'bagging_fraction': 0.4502890231195096}\n",
      "0.759055 (0.010847) with: {'min_data_in_leaf': 485, 'max_depth': 6, 'learning_rate': 0.029481129373032353, 'lambda_l1': 0.9741394741652668, 'feature_fraction': 0.9927102934372364, 'bagging_fraction': 0.4968805090171967}\n",
      "0.885039 (0.013806) with: {'min_data_in_leaf': 46, 'max_depth': 24, 'learning_rate': 0.024954384929868505, 'lambda_l1': 0.0015046261290527774, 'feature_fraction': 0.5953457734590281, 'bagging_fraction': 0.8513149074233138}\n",
      "0.877165 (0.011305) with: {'min_data_in_leaf': 167, 'max_depth': 16, 'learning_rate': 0.09870127105888815, 'lambda_l1': 0.7268509968724453, 'feature_fraction': 0.3872491725088238, 'bagging_fraction': 0.32322812469430157}\n",
      "0.871916 (0.011892) with: {'min_data_in_leaf': 225, 'max_depth': 7, 'learning_rate': 0.08118751445096514, 'lambda_l1': 0.03735765092636889, 'feature_fraction': 0.5609571579118078, 'bagging_fraction': 0.4336778841636613}\n",
      "0.884252 (0.009545) with: {'min_data_in_leaf': 39, 'max_depth': 16, 'learning_rate': 0.04749177476366165, 'lambda_l1': 0.768540095608294, 'feature_fraction': 0.281920071319123, 'bagging_fraction': 0.7360970836771801}\n",
      "0.854068 (0.012911) with: {'min_data_in_leaf': 280, 'max_depth': 15, 'learning_rate': 0.06289115956502811, 'lambda_l1': 0.0015046261290527774, 'feature_fraction': 0.7405727776842674, 'bagging_fraction': 0.6689985549776225}\n",
      "0.838583 (0.008779) with: {'min_data_in_leaf': 266, 'max_depth': 22, 'learning_rate': 0.038862739908887584, 'lambda_l1': 0.47874510710140716, 'feature_fraction': 0.9088838105716656, 'bagging_fraction': 0.8887038704340252}\n",
      "0.845407 (0.010900) with: {'min_data_in_leaf': 334, 'max_depth': 7, 'learning_rate': 0.07098742521114479, 'lambda_l1': 0.7092379501829046, 'feature_fraction': 0.7562677301087982, 'bagging_fraction': 0.9951392141692306}\n",
      "0.825722 (0.014453) with: {'min_data_in_leaf': 396, 'max_depth': 14, 'learning_rate': 0.05484014735793823, 'lambda_l1': 0.4995878322102484, 'feature_fraction': 0.39314961511831553, 'bagging_fraction': 0.8513149074233138}\n",
      "0.819160 (0.009264) with: {'min_data_in_leaf': 304, 'max_depth': 21, 'learning_rate': 0.03291133109983079, 'lambda_l1': 0.5542296387939777, 'feature_fraction': 0.8895086996955018, 'bagging_fraction': 0.3047433129511328}\n",
      "0.883727 (0.013193) with: {'min_data_in_leaf': 94, 'max_depth': 15, 'learning_rate': 0.04749177476366165, 'lambda_l1': 0.16133732882115526, 'feature_fraction': 0.6820130091228254, 'bagging_fraction': 0.4566693533293191}\n",
      "0.880315 (0.010633) with: {'min_data_in_leaf': 167, 'max_depth': 21, 'learning_rate': 0.07753658823149953, 'lambda_l1': 0.2748542011089876, 'feature_fraction': 0.688558420117676, 'bagging_fraction': 0.7958742662602173}\n",
      "0.864304 (0.014279) with: {'min_data_in_leaf': 266, 'max_depth': 21, 'learning_rate': 0.08089758967843194, 'lambda_l1': 0.5146331823407098, 'feature_fraction': 0.6069237551235968, 'bagging_fraction': 0.9520115309186076}\n",
      "0.887664 (0.013513) with: {'min_data_in_leaf': 60, 'max_depth': 9, 'learning_rate': 0.07630480234956652, 'lambda_l1': 0.28451503882070794, 'feature_fraction': 0.9015086291625375, 'bagging_fraction': 0.34910546997627084}\n",
      "0.866404 (0.013809) with: {'min_data_in_leaf': 249, 'max_depth': 6, 'learning_rate': 0.07098742521114479, 'lambda_l1': 0.06769800845082086, 'feature_fraction': 0.44317463850325417, 'bagging_fraction': 0.45984689446504384}\n",
      "0.834646 (0.008297) with: {'min_data_in_leaf': 358, 'max_depth': 6, 'learning_rate': 0.05484014735793823, 'lambda_l1': 0.16133732882115526, 'feature_fraction': 0.8460950802136225, 'bagging_fraction': 0.742168386368243}\n",
      "0.742782 (0.012231) with: {'min_data_in_leaf': 280, 'max_depth': 10, 'learning_rate': 0.013069989674861475, 'lambda_l1': 0.5686982338916955, 'feature_fraction': 0.7573720317174075, 'bagging_fraction': 0.7360970836771801}\n",
      "0.889501 (0.014777) with: {'min_data_in_leaf': 80, 'max_depth': 19, 'learning_rate': 0.09278280599748451, 'lambda_l1': 0.16133732882115526, 'feature_fraction': 0.5099201858168457, 'bagging_fraction': 0.8551916590457058}\n",
      "0.849869 (0.011291) with: {'min_data_in_leaf': 265, 'max_depth': 20, 'learning_rate': 0.04749177476366165, 'lambda_l1': 0.3719187133676075, 'feature_fraction': 0.688558420117676, 'bagging_fraction': 0.7067363239675439}\n",
      "0.769029 (0.008661) with: {'min_data_in_leaf': 470, 'max_depth': 20, 'learning_rate': 0.029481129373032353, 'lambda_l1': 0.2586558749598573, 'feature_fraction': 0.47705075075993436, 'bagging_fraction': 0.6738601112210277}\n",
      "0.811549 (0.010968) with: {'min_data_in_leaf': 180, 'max_depth': 7, 'learning_rate': 0.01850410129981584, 'lambda_l1': 0.8820111581615196, 'feature_fraction': 0.7646600384009693, 'bagging_fraction': 0.3418245002473473}\n",
      "0.835958 (0.013661) with: {'min_data_in_leaf': 433, 'max_depth': 22, 'learning_rate': 0.086161762527122, 'lambda_l1': 0.2748542011089876, 'feature_fraction': 0.5641027998858984, 'bagging_fraction': 0.6384020183526238}\n",
      "0.884252 (0.014008) with: {'min_data_in_leaf': 69, 'max_depth': 10, 'learning_rate': 0.08422271296560567, 'lambda_l1': 0.4680790035784811, 'feature_fraction': 0.4186226386680377, 'bagging_fraction': 0.39637642980329024}\n",
      "0.860630 (0.012348) with: {'min_data_in_leaf': 267, 'max_depth': 22, 'learning_rate': 0.07642417764245664, 'lambda_l1': 0.42679807656157, 'feature_fraction': 0.28964755509472884, 'bagging_fraction': 0.2530226444644543}\n",
      "0.813648 (0.009903) with: {'min_data_in_leaf': 466, 'max_depth': 8, 'learning_rate': 0.062163945718464696, 'lambda_l1': 0.18050660651594785, 'feature_fraction': 0.36543150365880905, 'bagging_fraction': 0.9292989475415088}\n",
      "0.876115 (0.012820) with: {'min_data_in_leaf': 172, 'max_depth': 6, 'learning_rate': 0.06279742999723735, 'lambda_l1': 0.4923777038258458, 'feature_fraction': 0.3149140591340587, 'bagging_fraction': 0.3308204638264613}\n",
      "0.878478 (0.012957) with: {'min_data_in_leaf': 95, 'max_depth': 15, 'learning_rate': 0.038938302509715805, 'lambda_l1': 0.8014377513314559, 'feature_fraction': 0.286399698297305, 'bagging_fraction': 0.734074075586154}\n",
      "0.803150 (0.012592) with: {'min_data_in_leaf': 417, 'max_depth': 18, 'learning_rate': 0.0406280445523634, 'lambda_l1': 0.8991190407751606, 'feature_fraction': 0.7226462560789778, 'bagging_fraction': 0.34868338975908963}\n",
      "0.860630 (0.016142) with: {'min_data_in_leaf': 266, 'max_depth': 19, 'learning_rate': 0.08261805826337704, 'lambda_l1': 0.5542296387939777, 'feature_fraction': 0.44317463850325417, 'bagging_fraction': 0.5130894826934904}\n",
      "0.829134 (0.014229) with: {'min_data_in_leaf': 417, 'max_depth': 7, 'learning_rate': 0.07277215741400064, 'lambda_l1': 0.768540095608294, 'feature_fraction': 0.7063936404422937, 'bagging_fraction': 0.40885683334968015}\n",
      "0.810236 (0.010133) with: {'min_data_in_leaf': 249, 'max_depth': 19, 'learning_rate': 0.023345956962948167, 'lambda_l1': 0.7092379501829046, 'feature_fraction': 0.31895953602368793, 'bagging_fraction': 0.7448893139261881}\n",
      "0.872966 (0.010945) with: {'min_data_in_leaf': 138, 'max_depth': 9, 'learning_rate': 0.037020389351308185, 'lambda_l1': 0.05123431330436523, 'feature_fraction': 0.5785248419232365, 'bagging_fraction': 0.43278237886373955}\n",
      "0.808661 (0.015316) with: {'min_data_in_leaf': 326, 'max_depth': 20, 'learning_rate': 0.029481129373032353, 'lambda_l1': 0.5741268985393458, 'feature_fraction': 0.5148130977353862, 'bagging_fraction': 0.5177903735171021}\n",
      "0.869554 (0.009455) with: {'min_data_in_leaf': 98, 'max_depth': 9, 'learning_rate': 0.026611196581581426, 'lambda_l1': 0.33459079555609617, 'feature_fraction': 0.362001684372141, 'bagging_fraction': 0.8395581025310357}\n",
      "0.659580 (0.016469) with: {'min_data_in_leaf': 86, 'max_depth': 14, 'learning_rate': 0.001640671448276203, 'lambda_l1': 0.474254957273592, 'feature_fraction': 0.7856737471426095, 'bagging_fraction': 0.3302284216934376}\n",
      "0.820735 (0.008423) with: {'min_data_in_leaf': 113, 'max_depth': 14, 'learning_rate': 0.013041167376500828, 'lambda_l1': 0.474254957273592, 'feature_fraction': 0.4465587851298521, 'bagging_fraction': 0.9914894367429908}\n",
      "0.788976 (0.014585) with: {'min_data_in_leaf': 452, 'max_depth': 7, 'learning_rate': 0.0377772411048523, 'lambda_l1': 0.8379940256168908, 'feature_fraction': 0.7562677301087982, 'bagging_fraction': 0.25846794883628976}\n",
      "0.889239 (0.009487) with: {'min_data_in_leaf': 46, 'max_depth': 16, 'learning_rate': 0.09391968177530917, 'lambda_l1': 0.3716244387000136, 'feature_fraction': 0.41392125073906955, 'bagging_fraction': 0.6384020183526238}\n",
      "0.350131 (0.009652) with: {'min_data_in_leaf': 499, 'max_depth': 24, 'learning_rate': 0.0005596910141484465, 'lambda_l1': 0.8058947484594089, 'feature_fraction': 0.624311022570671, 'bagging_fraction': 0.9292989475415088}\n",
      "0.878740 (0.010273) with: {'min_data_in_leaf': 94, 'max_depth': 21, 'learning_rate': 0.06279742999723735, 'lambda_l1': 0.4995878322102484, 'feature_fraction': 0.9934544288282473, 'bagging_fraction': 0.8513149074233138}\n",
      "0.851969 (0.009178) with: {'min_data_in_leaf': 368, 'max_depth': 18, 'learning_rate': 0.08261805826337704, 'lambda_l1': 0.26180352875923674, 'feature_fraction': 0.3149140591340587, 'bagging_fraction': 0.25050015015989824}\n",
      "0.866667 (0.011618) with: {'min_data_in_leaf': 229, 'max_depth': 16, 'learning_rate': 0.05689404942818664, 'lambda_l1': 0.0229168725707376, 'feature_fraction': 0.32555869865238724, 'bagging_fraction': 0.4502890231195096}\n",
      "0.791339 (0.011636) with: {'min_data_in_leaf': 473, 'max_depth': 13, 'learning_rate': 0.03947135805337951, 'lambda_l1': 0.1395855061472674, 'feature_fraction': 0.635260910304736, 'bagging_fraction': 0.3047433129511328}\n",
      "0.882152 (0.012104) with: {'min_data_in_leaf': 100, 'max_depth': 20, 'learning_rate': 0.06772179392405428, 'lambda_l1': 0.768540095608294, 'feature_fraction': 0.6083293190678971, 'bagging_fraction': 0.8049894149691099}\n",
      "0.876640 (0.009651) with: {'min_data_in_leaf': 55, 'max_depth': 23, 'learning_rate': 0.021870093343914106, 'lambda_l1': 0.36563369104357557, 'feature_fraction': 0.37804692600968426, 'bagging_fraction': 0.7360970836771801}\n",
      "0.880315 (0.011748) with: {'min_data_in_leaf': 43, 'max_depth': 7, 'learning_rate': 0.07543608285431669, 'lambda_l1': 0.42679807656157, 'feature_fraction': 0.8097520112238722, 'bagging_fraction': 0.5035680180174651}\n",
      "0.820472 (0.007395) with: {'min_data_in_leaf': 138, 'max_depth': 24, 'learning_rate': 0.015137466344528049, 'lambda_l1': 0.3716244387000136, 'feature_fraction': 0.36123770532301147, 'bagging_fraction': 0.5408959038385701}\n",
      "0.864304 (0.014989) with: {'min_data_in_leaf': 180, 'max_depth': 20, 'learning_rate': 0.03947135805337951, 'lambda_l1': 0.5627837328996755, 'feature_fraction': 0.565231679676507, 'bagging_fraction': 0.9380905528605239}\n",
      "0.806562 (0.006884) with: {'min_data_in_leaf': 431, 'max_depth': 14, 'learning_rate': 0.04753643246415883, 'lambda_l1': 0.42679807656157, 'feature_fraction': 0.3418930712499858, 'bagging_fraction': 0.45986133006535646}\n",
      "0.857480 (0.010133) with: {'min_data_in_leaf': 234, 'max_depth': 7, 'learning_rate': 0.04544626322739714, 'lambda_l1': 0.30495535472261937, 'feature_fraction': 0.5985626632600937, 'bagging_fraction': 0.7184856339205163}\n",
      "0.863780 (0.011084) with: {'min_data_in_leaf': 273, 'max_depth': 22, 'learning_rate': 0.09870127105888815, 'lambda_l1': 0.36029345237894495, 'feature_fraction': 0.8948059117577606, 'bagging_fraction': 0.868506811716675}\n",
      "0.897375 (0.012029) with: {'min_data_in_leaf': 39, 'max_depth': 15, 'learning_rate': 0.07642417764245664, 'lambda_l1': 0.002513522513178712, 'feature_fraction': 0.5649369933980897, 'bagging_fraction': 0.5130894826934904}\n",
      "0.884252 (0.009991) with: {'min_data_in_leaf': 19, 'max_depth': 16, 'learning_rate': 0.021870093343914106, 'lambda_l1': 0.6388416558270174, 'feature_fraction': 0.6412408193430215, 'bagging_fraction': 0.7294283574127564}\n",
      "0.854856 (0.011138) with: {'min_data_in_leaf': 268, 'max_depth': 23, 'learning_rate': 0.051962895756180065, 'lambda_l1': 0.002513522513178712, 'feature_fraction': 0.8957153985016165, 'bagging_fraction': 0.6384020183526238}\n",
      "0.872703 (0.015373) with: {'min_data_in_leaf': 180, 'max_depth': 15, 'learning_rate': 0.06279742999723735, 'lambda_l1': 0.9299752272368015, 'feature_fraction': 0.7562677301087982, 'bagging_fraction': 0.734074075586154}\n",
      "0.818110 (0.012273) with: {'min_data_in_leaf': 368, 'max_depth': 9, 'learning_rate': 0.0377772411048523, 'lambda_l1': 0.002513522513178712, 'feature_fraction': 0.46622156748741933, 'bagging_fraction': 0.9417327193045877}\n",
      "0.794488 (0.011101) with: {'min_data_in_leaf': 172, 'max_depth': 15, 'learning_rate': 0.013912138308510836, 'lambda_l1': 0.3366165618496434, 'feature_fraction': 0.3608807484797719, 'bagging_fraction': 0.43823116841480947}\n",
      "0.856430 (0.010286) with: {'min_data_in_leaf': 234, 'max_depth': 7, 'learning_rate': 0.051962895756180065, 'lambda_l1': 0.4054817579814104, 'feature_fraction': 0.7572436586732458, 'bagging_fraction': 0.9004617349778057}\n",
      "0.856430 (0.010376) with: {'min_data_in_leaf': 323, 'max_depth': 23, 'learning_rate': 0.07543608285431669, 'lambda_l1': 0.2840345436239562, 'feature_fraction': 0.5759535734849829, 'bagging_fraction': 0.3077214751506768}\n",
      "0.876115 (0.011845) with: {'min_data_in_leaf': 229, 'max_depth': 15, 'learning_rate': 0.09690037316988012, 'lambda_l1': 0.16133732882115526, 'feature_fraction': 0.45652194155443326, 'bagging_fraction': 0.9557101498470986}\n",
      "0.846982 (0.011000) with: {'min_data_in_leaf': 334, 'max_depth': 15, 'learning_rate': 0.07099840729098683, 'lambda_l1': 0.9352065412738418, 'feature_fraction': 0.3418930712499858, 'bagging_fraction': 0.5727781337792712}\n",
      "0.649081 (0.014189) with: {'min_data_in_leaf': 418, 'max_depth': 19, 'learning_rate': 0.008247096193880924, 'lambda_l1': 0.7185708493539409, 'feature_fraction': 0.8948059117577606, 'bagging_fraction': 0.25846794883628976}\n",
      "0.881102 (0.011772) with: {'min_data_in_leaf': 95, 'max_depth': 9, 'learning_rate': 0.07543608285431669, 'lambda_l1': 0.6783354830490685, 'feature_fraction': 0.7591470118014184, 'bagging_fraction': 0.8513149074233138}\n",
      "0.846719 (0.011578) with: {'min_data_in_leaf': 335, 'max_depth': 14, 'learning_rate': 0.08371533590361077, 'lambda_l1': 0.8014377513314559, 'feature_fraction': 0.5442673947768529, 'bagging_fraction': 0.34868338975908963}\n",
      "0.676115 (0.012672) with: {'min_data_in_leaf': 357, 'max_depth': 21, 'learning_rate': 0.010243751015885016, 'lambda_l1': 0.07158928791812136, 'feature_fraction': 0.31895953602368793, 'bagging_fraction': 0.27871779271416575}\n",
      "0.887139 (0.012073) with: {'min_data_in_leaf': 113, 'max_depth': 7, 'learning_rate': 0.08547409621260693, 'lambda_l1': 0.05123431330436523, 'feature_fraction': 0.5799558657673334, 'bagging_fraction': 0.868506811716675}\n",
      "0.865354 (0.009971) with: {'min_data_in_leaf': 76, 'max_depth': 10, 'learning_rate': 0.01974228954292596, 'lambda_l1': 0.03219018219763703, 'feature_fraction': 0.6410139541993087, 'bagging_fraction': 0.37209448530230227}\n",
      "0.679790 (0.017423) with: {'min_data_in_leaf': 269, 'max_depth': 24, 'learning_rate': 0.0062423048978776825, 'lambda_l1': 0.4054817579814104, 'feature_fraction': 0.8460950802136225, 'bagging_fraction': 0.25846794883628976}\n",
      "0.848294 (0.010608) with: {'min_data_in_leaf': 357, 'max_depth': 13, 'learning_rate': 0.08371533590361077, 'lambda_l1': 0.9258939609762522, 'feature_fraction': 0.41407765876503005, 'bagging_fraction': 0.5408959038385701}\n",
      "0.884777 (0.014543) with: {'min_data_in_leaf': 43, 'max_depth': 8, 'learning_rate': 0.09657260984210976, 'lambda_l1': 0.3781184152711966, 'feature_fraction': 0.5641027998858984, 'bagging_fraction': 0.932705291267405}\n",
      "0.708399 (0.011862) with: {'min_data_in_leaf': 94, 'max_depth': 20, 'learning_rate': 0.002459362126359497, 'lambda_l1': 0.36029345237894495, 'feature_fraction': 0.2892884495785184, 'bagging_fraction': 0.6738601112210277}\n",
      "0.874803 (0.010385) with: {'min_data_in_leaf': 95, 'max_depth': 19, 'learning_rate': 0.04753643246415883, 'lambda_l1': 0.5743965126768239, 'feature_fraction': 0.9927102934372364, 'bagging_fraction': 0.419992582285333}\n",
      "0.879265 (0.014381) with: {'min_data_in_leaf': 69, 'max_depth': 19, 'learning_rate': 0.037020389351308185, 'lambda_l1': 0.561728059448168, 'feature_fraction': 0.9015086291625375, 'bagging_fraction': 0.32322812469430157}\n",
      "0.826509 (0.014552) with: {'min_data_in_leaf': 466, 'max_depth': 8, 'learning_rate': 0.08422271296560567, 'lambda_l1': 0.7381059992184543, 'feature_fraction': 0.4573511343558394, 'bagging_fraction': 0.4662078680075106}\n",
      "0.874803 (0.011825) with: {'min_data_in_leaf': 199, 'max_depth': 16, 'learning_rate': 0.07098742521114479, 'lambda_l1': 0.37112241607033514, 'feature_fraction': 0.46622156748741933, 'bagging_fraction': 0.8395581025310357}\n",
      "0.769554 (0.014086) with: {'min_data_in_leaf': 417, 'max_depth': 22, 'learning_rate': 0.026611196581581426, 'lambda_l1': 0.03647146803495993, 'feature_fraction': 0.26918461598142596, 'bagging_fraction': 0.6689985549776225}\n",
      "0.840420 (0.009514) with: {'min_data_in_leaf': 227, 'max_depth': 21, 'learning_rate': 0.0339343234712795, 'lambda_l1': 0.6170347546607704, 'feature_fraction': 0.688558420117676, 'bagging_fraction': 0.474008781815512}\n",
      "0.888189 (0.009426) with: {'min_data_in_leaf': 19, 'max_depth': 8, 'learning_rate': 0.06289115956502811, 'lambda_l1': 0.5146331823407098, 'feature_fraction': 0.688558420117676, 'bagging_fraction': 0.8365926208807126}\n",
      "0.841470 (0.009668) with: {'min_data_in_leaf': 444, 'max_depth': 19, 'learning_rate': 0.09391968177530917, 'lambda_l1': 0.33459079555609617, 'feature_fraction': 0.37804692600968426, 'bagging_fraction': 0.7805946046971775}\n",
      "0.804199 (0.012649) with: {'min_data_in_leaf': 466, 'max_depth': 22, 'learning_rate': 0.051962895756180065, 'lambda_l1': 0.44364921142671776, 'feature_fraction': 0.635260910304736, 'bagging_fraction': 0.8963129802457994}\n",
      "0.779003 (0.008041) with: {'min_data_in_leaf': 485, 'max_depth': 23, 'learning_rate': 0.037020389351308185, 'lambda_l1': 0.7676138603555922, 'feature_fraction': 0.4573511343558394, 'bagging_fraction': 0.742168386368243}\n",
      "0.885827 (0.016608) with: {'min_data_in_leaf': 180, 'max_depth': 19, 'learning_rate': 0.09690037316988012, 'lambda_l1': 0.03735765092636889, 'feature_fraction': 0.635260910304736, 'bagging_fraction': 0.46398991851214666}\n",
      "0.877953 (0.009552) with: {'min_data_in_leaf': 89, 'max_depth': 23, 'learning_rate': 0.07789296092376309, 'lambda_l1': 0.8269453104529011, 'feature_fraction': 0.8419435194614723, 'bagging_fraction': 0.945885930099219}\n",
      "0.884777 (0.014470) with: {'min_data_in_leaf': 43, 'max_depth': 6, 'learning_rate': 0.050057432807981334, 'lambda_l1': 0.0229168725707376, 'feature_fraction': 0.6083293190678971, 'bagging_fraction': 0.9557101498470986}\n",
      "0.871129 (0.012907) with: {'min_data_in_leaf': 249, 'max_depth': 7, 'learning_rate': 0.09278280599748451, 'lambda_l1': 0.5627837328996755, 'feature_fraction': 0.32555869865238724, 'bagging_fraction': 0.3047433129511328}\n",
      "0.844882 (0.010096) with: {'min_data_in_leaf': 315, 'max_depth': 13, 'learning_rate': 0.0631899657022023, 'lambda_l1': 0.712443534911368, 'feature_fraction': 0.5799558657673334, 'bagging_fraction': 0.8887038704340252}\n",
      "0.858005 (0.011398) with: {'min_data_in_leaf': 265, 'max_depth': 7, 'learning_rate': 0.06388548639690404, 'lambda_l1': 0.44364921142671776, 'feature_fraction': 0.5785248419232365, 'bagging_fraction': 0.8112232384116959}\n",
      "0.892126 (0.010851) with: {'min_data_in_leaf': 28, 'max_depth': 11, 'learning_rate': 0.026611196581581426, 'lambda_l1': 0.3346990270509439, 'feature_fraction': 0.32555869865238724, 'bagging_fraction': 0.9380905528605239}\n",
      "0.886614 (0.011843) with: {'min_data_in_leaf': 76, 'max_depth': 24, 'learning_rate': 0.062163945718464696, 'lambda_l1': 0.712443534911368, 'feature_fraction': 0.28964755509472884, 'bagging_fraction': 0.5408959038385701}\n",
      "0.834646 (0.016544) with: {'min_data_in_leaf': 404, 'max_depth': 7, 'learning_rate': 0.07098742521114479, 'lambda_l1': 0.4617051468784279, 'feature_fraction': 0.45652194155443326, 'bagging_fraction': 0.5177903735171021}\n",
      "0.880840 (0.014342) with: {'min_data_in_leaf': 108, 'max_depth': 20, 'learning_rate': 0.08118751445096514, 'lambda_l1': 0.4995878322102484, 'feature_fraction': 0.4465587851298521, 'bagging_fraction': 0.474008781815512}\n",
      "0.887139 (0.012362) with: {'min_data_in_leaf': 86, 'max_depth': 14, 'learning_rate': 0.09740496522804008, 'lambda_l1': 0.4995878322102484, 'feature_fraction': 0.45652194155443326, 'bagging_fraction': 0.8887038704340252}\n",
      "0.875328 (0.011664) with: {'min_data_in_leaf': 103, 'max_depth': 21, 'learning_rate': 0.04749177476366165, 'lambda_l1': 0.8820111581615196, 'feature_fraction': 0.7226462560789778, 'bagging_fraction': 0.9914894367429908}\n",
      "0.864304 (0.011612) with: {'min_data_in_leaf': 297, 'max_depth': 7, 'learning_rate': 0.09657260984210976, 'lambda_l1': 0.013254460525070733, 'feature_fraction': 0.5148130977353862, 'bagging_fraction': 0.7294283574127564}\n",
      "0.822572 (0.010120) with: {'min_data_in_leaf': 266, 'max_depth': 7, 'learning_rate': 0.030272023334673465, 'lambda_l1': 0.5069748646478869, 'feature_fraction': 0.46622156748741933, 'bagging_fraction': 0.39972841597924325}\n",
      "0.870079 (0.009928) with: {'min_data_in_leaf': 148, 'max_depth': 13, 'learning_rate': 0.036200948890434605, 'lambda_l1': 0.3719187133676075, 'feature_fraction': 0.44317463850325417, 'bagging_fraction': 0.9557101498470986}\n",
      "0.867454 (0.014525) with: {'min_data_in_leaf': 19, 'max_depth': 14, 'learning_rate': 0.013069989674861475, 'lambda_l1': 0.1453842513361342, 'feature_fraction': 0.9927102934372364, 'bagging_fraction': 0.5018624408577049}\n",
      "0.497900 (0.010737) with: {'min_data_in_leaf': 105, 'max_depth': 11, 'learning_rate': 0.0005596910141484465, 'lambda_l1': 0.0229168725707376, 'feature_fraction': 0.36543150365880905, 'bagging_fraction': 0.6384020183526238}\n",
      "0.868241 (0.011946) with: {'min_data_in_leaf': 234, 'max_depth': 14, 'learning_rate': 0.09657260984210976, 'lambda_l1': 0.8820111581615196, 'feature_fraction': 0.970658530278233, 'bagging_fraction': 0.3418245002473473}\n",
      "0.710499 (0.011063) with: {'min_data_in_leaf': 267, 'max_depth': 14, 'learning_rate': 0.009378159977376453, 'lambda_l1': 0.0015046261290527774, 'feature_fraction': 0.7562677301087982, 'bagging_fraction': 0.5479228477916047}\n",
      "0.694488 (0.014327) with: {'min_data_in_leaf': 351, 'max_depth': 11, 'learning_rate': 0.011476906105266986, 'lambda_l1': 0.6170347546607704, 'feature_fraction': 0.46351951866819574, 'bagging_fraction': 0.6554462045441563}\n",
      "0.881627 (0.013046) with: {'min_data_in_leaf': 86, 'max_depth': 19, 'learning_rate': 0.03291133109983079, 'lambda_l1': 0.33459079555609617, 'feature_fraction': 0.362001684372141, 'bagging_fraction': 0.8161691192505147}\n",
      "0.861680 (0.011262) with: {'min_data_in_leaf': 274, 'max_depth': 11, 'learning_rate': 0.07630480234956652, 'lambda_l1': 0.37112241607033514, 'feature_fraction': 0.7447334193718799, 'bagging_fraction': 0.8513149074233138}\n",
      "0.859843 (0.010140) with: {'min_data_in_leaf': 234, 'max_depth': 18, 'learning_rate': 0.07099840729098683, 'lambda_l1': 0.7185708493539409, 'feature_fraction': 0.7606770365117717, 'bagging_fraction': 0.37209448530230227}\n",
      "0.646194 (0.021854) with: {'min_data_in_leaf': 104, 'max_depth': 18, 'learning_rate': 0.001640671448276203, 'lambda_l1': 0.14072600320354067, 'feature_fraction': 0.483418773988896, 'bagging_fraction': 0.3939980126973871}\n",
      "0.883465 (0.009479) with: {'min_data_in_leaf': 106, 'max_depth': 24, 'learning_rate': 0.05088177687700322, 'lambda_l1': 0.48000990586859427, 'feature_fraction': 0.3658952971465034, 'bagging_fraction': 0.5177903735171021}\n",
      "0.827559 (0.015095) with: {'min_data_in_leaf': 368, 'max_depth': 13, 'learning_rate': 0.05349035900089145, 'lambda_l1': 0.6766385237720431, 'feature_fraction': 0.4573511343558394, 'bagging_fraction': 0.7067363239675439}\n",
      "0.816273 (0.011816) with: {'min_data_in_leaf': 493, 'max_depth': 21, 'learning_rate': 0.07098742521114479, 'lambda_l1': 0.3366165618496434, 'feature_fraction': 0.6083293190678971, 'bagging_fraction': 0.6384020183526238}\n",
      "0.775853 (0.008759) with: {'min_data_in_leaf': 487, 'max_depth': 22, 'learning_rate': 0.036200948890434605, 'lambda_l1': 0.5795473889441491, 'feature_fraction': 0.36543150365880905, 'bagging_fraction': 0.43278237886373955}\n",
      "0.831496 (0.012011) with: {'min_data_in_leaf': 350, 'max_depth': 20, 'learning_rate': 0.050057432807981334, 'lambda_l1': 0.6811459995923554, 'feature_fraction': 0.688558420117676, 'bagging_fraction': 0.4566693533293191}\n",
      "0.797900 (0.009807) with: {'min_data_in_leaf': 146, 'max_depth': 13, 'learning_rate': 0.012809914271212034, 'lambda_l1': 0.5686982338916955, 'feature_fraction': 0.6083293190678971, 'bagging_fraction': 0.8537518674305191}\n",
      "0.819685 (0.009895) with: {'min_data_in_leaf': 317, 'max_depth': 24, 'learning_rate': 0.034957123922740516, 'lambda_l1': 0.4495089235411983, 'feature_fraction': 0.47705075075993436, 'bagging_fraction': 0.9951392141692306}\n",
      "0.833858 (0.009663) with: {'min_data_in_leaf': 266, 'max_depth': 15, 'learning_rate': 0.037020389351308185, 'lambda_l1': 0.9352065412738418, 'feature_fraction': 0.6146175380529777, 'bagging_fraction': 0.9738282828691349}\n",
      "0.882152 (0.009385) with: {'min_data_in_leaf': 105, 'max_depth': 20, 'learning_rate': 0.08371533590361077, 'lambda_l1': 0.5627837328996755, 'feature_fraction': 0.6410139541993087, 'bagging_fraction': 0.742168386368243}\n",
      "0.881102 (0.011401) with: {'min_data_in_leaf': 111, 'max_depth': 10, 'learning_rate': 0.05484014735793823, 'lambda_l1': 0.5686982338916955, 'feature_fraction': 0.7856737471426095, 'bagging_fraction': 0.6406590331277203}\n",
      "0.874016 (0.010573) with: {'min_data_in_leaf': 35, 'max_depth': 22, 'learning_rate': 0.017929787694683244, 'lambda_l1': 0.6388416558270174, 'feature_fraction': 0.7336787831311864, 'bagging_fraction': 0.9292989475415088}\n",
      "0.873491 (0.011041) with: {'min_data_in_leaf': 148, 'max_depth': 18, 'learning_rate': 0.03734756670129417, 'lambda_l1': 0.12111758030678055, 'feature_fraction': 0.970658530278233, 'bagging_fraction': 0.5773093966214555}\n",
      "0.873228 (0.014161) with: {'min_data_in_leaf': 200, 'max_depth': 20, 'learning_rate': 0.09411945114340523, 'lambda_l1': 0.5743965126768239, 'feature_fraction': 0.8957153985016165, 'bagging_fraction': 0.38339233561184966}\n",
      "0.833071 (0.010734) with: {'min_data_in_leaf': 415, 'max_depth': 9, 'learning_rate': 0.06772179392405428, 'lambda_l1': 0.14072600320354067, 'feature_fraction': 0.2892884495785184, 'bagging_fraction': 0.37209448530230227}\n",
      "0.884252 (0.011705) with: {'min_data_in_leaf': 80, 'max_depth': 21, 'learning_rate': 0.07543608285431669, 'lambda_l1': 0.7529996916088938, 'feature_fraction': 0.31895953602368793, 'bagging_fraction': 0.8049894149691099}\n",
      "0.820735 (0.011104) with: {'min_data_in_leaf': 249, 'max_depth': 19, 'learning_rate': 0.02578851154951003, 'lambda_l1': 0.03219018219763703, 'feature_fraction': 0.9234368064719956, 'bagging_fraction': 0.734074075586154}\n",
      "0.865617 (0.012422) with: {'min_data_in_leaf': 249, 'max_depth': 7, 'learning_rate': 0.09657260984210976, 'lambda_l1': 0.768540095608294, 'feature_fraction': 0.2892884495785184, 'bagging_fraction': 0.3939980126973871}\n",
      "0.880840 (0.013215) with: {'min_data_in_leaf': 180, 'max_depth': 14, 'learning_rate': 0.09657260984210976, 'lambda_l1': 0.44364921142671776, 'feature_fraction': 0.8097520112238722, 'bagging_fraction': 0.7448893139261881}\n",
      "0.343832 (0.012668) with: {'min_data_in_leaf': 470, 'max_depth': 7, 'learning_rate': 0.0005596910141484465, 'lambda_l1': 0.7064718465056312, 'feature_fraction': 0.9234368064719956, 'bagging_fraction': 0.39637642980329024}\n",
      "0.825984 (0.011872) with: {'min_data_in_leaf': 358, 'max_depth': 22, 'learning_rate': 0.04753643246415883, 'lambda_l1': 0.2586558749598573, 'feature_fraction': 0.64900601925637, 'bagging_fraction': 0.9417327193045877}\n",
      "0.883465 (0.012058) with: {'min_data_in_leaf': 105, 'max_depth': 9, 'learning_rate': 0.05702857015428802, 'lambda_l1': 0.4626028587624069, 'feature_fraction': 0.45652194155443326, 'bagging_fraction': 0.8887038704340252}\n",
      "0.769554 (0.009828) with: {'min_data_in_leaf': 304, 'max_depth': 23, 'learning_rate': 0.01832045737332351, 'lambda_l1': 0.5805440342182874, 'feature_fraction': 0.565231679676507, 'bagging_fraction': 0.9520115309186076}\n",
      "0.752231 (0.009356) with: {'min_data_in_leaf': 473, 'max_depth': 8, 'learning_rate': 0.024954384929868505, 'lambda_l1': 0.712443534911368, 'feature_fraction': 0.6146175380529777, 'bagging_fraction': 0.3418245002473473}\n",
      "0.850656 (0.011526) with: {'min_data_in_leaf': 314, 'max_depth': 14, 'learning_rate': 0.08422271296560567, 'lambda_l1': 0.7838789207037316, 'feature_fraction': 0.46351951866819574, 'bagging_fraction': 0.9075514703703585}\n",
      "0.608399 (0.015806) with: {'min_data_in_leaf': 431, 'max_depth': 21, 'learning_rate': 0.005640434649582631, 'lambda_l1': 0.6783354830490685, 'feature_fraction': 0.5759535734849829, 'bagging_fraction': 0.868506811716675}\n",
      "0.873491 (0.012437) with: {'min_data_in_leaf': 89, 'max_depth': 8, 'learning_rate': 0.026611196581581426, 'lambda_l1': 0.03219018219763703, 'feature_fraction': 0.40834735857025983, 'bagging_fraction': 0.937578846314943}\n",
      "0.867454 (0.009293) with: {'min_data_in_leaf': 104, 'max_depth': 10, 'learning_rate': 0.026611196581581426, 'lambda_l1': 0.5686982338916955, 'feature_fraction': 0.39314961511831553, 'bagging_fraction': 0.7911635060829941}\n",
      "0.855643 (0.011783) with: {'min_data_in_leaf': 273, 'max_depth': 13, 'learning_rate': 0.05842234797404635, 'lambda_l1': 0.07158928791812136, 'feature_fraction': 0.8419435194614723, 'bagging_fraction': 0.25050015015989824}\n",
      "0.766667 (0.019849) with: {'min_data_in_leaf': 28, 'max_depth': 24, 'learning_rate': 0.001640671448276203, 'lambda_l1': 0.013254460525070733, 'feature_fraction': 0.828435138016004, 'bagging_fraction': 0.7184856339205163}\n",
      "0.840945 (0.012903) with: {'min_data_in_leaf': 420, 'max_depth': 16, 'learning_rate': 0.09015791681866688, 'lambda_l1': 0.002513522513178712, 'feature_fraction': 0.5609571579118078, 'bagging_fraction': 0.8049894149691099}\n",
      "0.828871 (0.010451) with: {'min_data_in_leaf': 418, 'max_depth': 18, 'learning_rate': 0.06772179392405428, 'lambda_l1': 0.539374732480692, 'feature_fraction': 0.8157350971483801, 'bagging_fraction': 0.6843887703813658}\n",
      "0.833071 (0.005705) with: {'min_data_in_leaf': 111, 'max_depth': 13, 'learning_rate': 0.015137466344528049, 'lambda_l1': 0.5741268985393458, 'feature_fraction': 0.7573720317174075, 'bagging_fraction': 0.8537518674305191}\n",
      "0.803937 (0.011963) with: {'min_data_in_leaf': 452, 'max_depth': 11, 'learning_rate': 0.045252763269019405, 'lambda_l1': 0.002513522513178712, 'feature_fraction': 0.5442673947768529, 'bagging_fraction': 0.868506811716675}\n",
      "0.890289 (0.012303) with: {'min_data_in_leaf': 10, 'max_depth': 10, 'learning_rate': 0.023345956962948167, 'lambda_l1': 0.1453842513361342, 'feature_fraction': 0.2892884495785184, 'bagging_fraction': 0.9380905528605239}\n",
      "0.874016 (0.014696) with: {'min_data_in_leaf': 167, 'max_depth': 16, 'learning_rate': 0.07944594599903744, 'lambda_l1': 0.5627837328996755, 'feature_fraction': 0.6820130091228254, 'bagging_fraction': 0.945885930099219}\n",
      "0.884777 (0.009450) with: {'min_data_in_leaf': 166, 'max_depth': 15, 'learning_rate': 0.09870127105888815, 'lambda_l1': 0.0229168725707376, 'feature_fraction': 0.46351951866819574, 'bagging_fraction': 0.5130894826934904}\n",
      "0.883465 (0.012518) with: {'min_data_in_leaf': 104, 'max_depth': 18, 'learning_rate': 0.036200948890434605, 'lambda_l1': 0.14072600320354067, 'feature_fraction': 0.6820130091228254, 'bagging_fraction': 0.7958742662602173}\n",
      "0.788714 (0.012527) with: {'min_data_in_leaf': 98, 'max_depth': 9, 'learning_rate': 0.008247096193880924, 'lambda_l1': 0.8991190407751606, 'feature_fraction': 0.7572436586732458, 'bagging_fraction': 0.868506811716675}\n",
      "0.666667 (0.013278) with: {'min_data_in_leaf': 368, 'max_depth': 14, 'learning_rate': 0.008247096193880924, 'lambda_l1': 0.5069748646478869, 'feature_fraction': 0.8553741661059728, 'bagging_fraction': 0.7805946046971775}\n",
      "0.854593 (0.006414) with: {'min_data_in_leaf': 148, 'max_depth': 6, 'learning_rate': 0.029481129373032353, 'lambda_l1': 0.33459079555609617, 'feature_fraction': 0.6146175380529777, 'bagging_fraction': 0.734074075586154}\n",
      "0.815486 (0.013770) with: {'min_data_in_leaf': 334, 'max_depth': 6, 'learning_rate': 0.03621606577038674, 'lambda_l1': 0.6170347546607704, 'feature_fraction': 0.7646600384009693, 'bagging_fraction': 0.5408959038385701}\n",
      "0.822572 (0.004861) with: {'min_data_in_leaf': 95, 'max_depth': 9, 'learning_rate': 0.012809914271212034, 'lambda_l1': 0.7185708493539409, 'feature_fraction': 0.7591470118014184, 'bagging_fraction': 0.8395581025310357}\n",
      "0.584777 (0.017529) with: {'min_data_in_leaf': 280, 'max_depth': 6, 'learning_rate': 0.002625807306753256, 'lambda_l1': 0.8014377513314559, 'feature_fraction': 0.362001684372141, 'bagging_fraction': 0.39637642980329024}\n",
      "0.734646 (0.012552) with: {'min_data_in_leaf': 420, 'max_depth': 6, 'learning_rate': 0.01974228954292596, 'lambda_l1': 0.8497457437298098, 'feature_fraction': 0.3149140591340587, 'bagging_fraction': 0.4968805090171967}\n",
      "0.879790 (0.011668) with: {'min_data_in_leaf': 113, 'max_depth': 18, 'learning_rate': 0.08438133513274937, 'lambda_l1': 0.7529996916088938, 'feature_fraction': 0.31895953602368793, 'bagging_fraction': 0.419992582285333}\n",
      "0.853018 (0.012743) with: {'min_data_in_leaf': 273, 'max_depth': 6, 'learning_rate': 0.062163945718464696, 'lambda_l1': 0.8820111581615196, 'feature_fraction': 0.6146175380529777, 'bagging_fraction': 0.7720398497026818}\n",
      "0.883465 (0.011680) with: {'min_data_in_leaf': 106, 'max_depth': 21, 'learning_rate': 0.055470557237504874, 'lambda_l1': 0.44364921142671776, 'feature_fraction': 0.362001684372141, 'bagging_fraction': 0.8348495665915322}\n",
      "0.867717 (0.013855) with: {'min_data_in_leaf': 138, 'max_depth': 10, 'learning_rate': 0.0377772411048523, 'lambda_l1': 0.7529996916088938, 'feature_fraction': 0.5786242598276711, 'bagging_fraction': 0.945885930099219}\n",
      "0.879003 (0.009832) with: {'min_data_in_leaf': 108, 'max_depth': 11, 'learning_rate': 0.07543608285431669, 'lambda_l1': 0.9352065412738418, 'feature_fraction': 0.37804692600968426, 'bagging_fraction': 0.43278237886373955}\n",
      "0.839108 (0.011339) with: {'min_data_in_leaf': 418, 'max_depth': 16, 'learning_rate': 0.09411945114340523, 'lambda_l1': 0.8014377513314559, 'feature_fraction': 0.7856737471426095, 'bagging_fraction': 0.3418245002473473}\n",
      "0.879003 (0.009652) with: {'min_data_in_leaf': 76, 'max_depth': 15, 'learning_rate': 0.030272023334673465, 'lambda_l1': 0.5743965126768239, 'feature_fraction': 0.362001684372141, 'bagging_fraction': 0.9557101498470986}\n",
      "0.880052 (0.014626) with: {'min_data_in_leaf': 69, 'max_depth': 20, 'learning_rate': 0.038862739908887584, 'lambda_l1': 0.6783354830490685, 'feature_fraction': 0.624311022570671, 'bagging_fraction': 0.8963129802457994}\n",
      "0.813648 (0.011152) with: {'min_data_in_leaf': 297, 'max_depth': 24, 'learning_rate': 0.027791123070923664, 'lambda_l1': 0.26180352875923674, 'feature_fraction': 0.39314961511831553, 'bagging_fraction': 0.5710774585859044}\n",
      "0.884514 (0.016085) with: {'min_data_in_leaf': 89, 'max_depth': 15, 'learning_rate': 0.05702857015428802, 'lambda_l1': 0.2698246642448642, 'feature_fraction': 0.8948059117577606, 'bagging_fraction': 0.3302284216934376}\n",
      "0.882677 (0.013712) with: {'min_data_in_leaf': 100, 'max_depth': 10, 'learning_rate': 0.05842234797404635, 'lambda_l1': 0.4495089235411983, 'feature_fraction': 0.688558420117676, 'bagging_fraction': 0.3418245002473473}\n",
      "0.830709 (0.010837) with: {'min_data_in_leaf': 314, 'max_depth': 8, 'learning_rate': 0.0406280445523634, 'lambda_l1': 0.1395855061472674, 'feature_fraction': 0.8460950802136225, 'bagging_fraction': 0.379705010170145}\n",
      "0.830446 (0.011946) with: {'min_data_in_leaf': 452, 'max_depth': 10, 'learning_rate': 0.08547409621260693, 'lambda_l1': 0.48000990586859427, 'feature_fraction': 0.635260910304736, 'bagging_fraction': 0.5018624408577049}\n",
      "0.866142 (0.008042) with: {'min_data_in_leaf': 225, 'max_depth': 22, 'learning_rate': 0.05193025728426503, 'lambda_l1': 0.3346990270509439, 'feature_fraction': 0.4465587851298521, 'bagging_fraction': 0.9507462768699241}\n",
      "0.666667 (0.015744) with: {'min_data_in_leaf': 335, 'max_depth': 7, 'learning_rate': 0.008247096193880924, 'lambda_l1': 0.26180352875923674, 'feature_fraction': 0.3872491725088238, 'bagging_fraction': 0.37209448530230227}\n",
      "0.875591 (0.011774) with: {'min_data_in_leaf': 111, 'max_depth': 14, 'learning_rate': 0.03947135805337951, 'lambda_l1': 0.5686982338916955, 'feature_fraction': 0.5785248419232365, 'bagging_fraction': 0.9292989475415088}\n",
      "0.830709 (0.005982) with: {'min_data_in_leaf': 273, 'max_depth': 23, 'learning_rate': 0.036200948890434605, 'lambda_l1': 0.7381059992184543, 'feature_fraction': 0.8157350971483801, 'bagging_fraction': 0.5479228477916047}\n",
      "0.816535 (0.009757) with: {'min_data_in_leaf': 485, 'max_depth': 22, 'learning_rate': 0.07277215741400064, 'lambda_l1': 0.6170347546607704, 'feature_fraction': 0.7910895473545941, 'bagging_fraction': 0.27871779271416575}\n",
      "0.831234 (0.010122) with: {'min_data_in_leaf': 63, 'max_depth': 22, 'learning_rate': 0.010243751015885016, 'lambda_l1': 0.7676138603555922, 'feature_fraction': 0.6454482851476008, 'bagging_fraction': 0.9417327193045877}\n",
      "0.751181 (0.014207) with: {'min_data_in_leaf': 222, 'max_depth': 8, 'learning_rate': 0.011476906105266986, 'lambda_l1': 0.36029345237894495, 'feature_fraction': 0.4465587851298521, 'bagging_fraction': 0.43823116841480947}\n",
      "0.873228 (0.011921) with: {'min_data_in_leaf': 199, 'max_depth': 15, 'learning_rate': 0.07069005269842409, 'lambda_l1': 0.44364921142671776, 'feature_fraction': 0.688558420117676, 'bagging_fraction': 0.8963129802457994}\n",
      "0.773228 (0.011631) with: {'min_data_in_leaf': 98, 'max_depth': 18, 'learning_rate': 0.005640434649582631, 'lambda_l1': 0.2698246642448642, 'feature_fraction': 0.3872491725088238, 'bagging_fraction': 0.3077214751506768}\n",
      "0.724147 (0.012110) with: {'min_data_in_leaf': 404, 'max_depth': 20, 'learning_rate': 0.01670425107586603, 'lambda_l1': 0.48777893105001313, 'feature_fraction': 0.45652194155443326, 'bagging_fraction': 0.7745208257132506}\n",
      "0.881627 (0.008586) with: {'min_data_in_leaf': 137, 'max_depth': 16, 'learning_rate': 0.09411945114340523, 'lambda_l1': 0.7838789207037316, 'feature_fraction': 0.3608807484797719, 'bagging_fraction': 0.868506811716675}\n",
      "0.839108 (0.014589) with: {'min_data_in_leaf': 396, 'max_depth': 9, 'learning_rate': 0.07630480234956652, 'lambda_l1': 0.6388416558270174, 'feature_fraction': 0.8553741661059728, 'bagging_fraction': 0.39972841597924325}\n",
      "0.880052 (0.012376) with: {'min_data_in_leaf': 69, 'max_depth': 21, 'learning_rate': 0.07069005269842409, 'lambda_l1': 0.7838789207037316, 'feature_fraction': 0.7405727776842674, 'bagging_fraction': 0.40885683334968015}\n",
      "0.882940 (0.012761) with: {'min_data_in_leaf': 43, 'max_depth': 7, 'learning_rate': 0.06388548639690404, 'lambda_l1': 0.7064718465056312, 'feature_fraction': 0.5148130977353862, 'bagging_fraction': 0.5408959038385701}\n",
      "0.859055 (0.010229) with: {'min_data_in_leaf': 267, 'max_depth': 13, 'learning_rate': 0.08118751445096514, 'lambda_l1': 0.5627837328996755, 'feature_fraction': 0.7336787831311864, 'bagging_fraction': 0.39972841597924325}\n",
      "0.699475 (0.016257) with: {'min_data_in_leaf': 267, 'max_depth': 14, 'learning_rate': 0.008247096193880924, 'lambda_l1': 0.30495535472261937, 'feature_fraction': 0.654983496819531, 'bagging_fraction': 0.8395581025310357}\n",
      "0.826509 (0.011838) with: {'min_data_in_leaf': 487, 'max_depth': 7, 'learning_rate': 0.09391968177530917, 'lambda_l1': 0.7381059992184543, 'feature_fraction': 0.828435138016004, 'bagging_fraction': 0.3077214751506768}\n",
      "0.880315 (0.014957) with: {'min_data_in_leaf': 180, 'max_depth': 23, 'learning_rate': 0.07944594599903744, 'lambda_l1': 0.2586558749598573, 'feature_fraction': 0.5456415642372383, 'bagging_fraction': 0.40885683334968015}\n",
      "0.855381 (0.007621) with: {'min_data_in_leaf': 137, 'max_depth': 21, 'learning_rate': 0.023345956962948167, 'lambda_l1': 0.06769800845082086, 'feature_fraction': 0.828435138016004, 'bagging_fraction': 0.25050015015989824}\n"
     ]
    }
   ],
   "source": [
    "# Random search\n",
    "max_depth = np.random.choice(range(6, 25), 17, replace=False)\n",
    "bagging_fraction = np.random.uniform(0.25, 1, 100)\n",
    "feature_fraction = np.random.uniform(0.25, 1, 100)\n",
    "min_data_in_leaf = np.random.choice(range(10, 500), 100, replace=False)\n",
    "lambda_l1 = np.random.uniform(0, 1, 100)\n",
    "learning_rate = np.random.uniform(0.0001, 0.1, 100)\n",
    "param_grid = dict(max_depth=max_depth, bagging_fraction=bagging_fraction, feature_fraction=feature_fraction, \n",
    "                  min_data_in_leaf=min_data_in_leaf, lambda_l1=lambda_l1, learning_rate=learning_rate)\n",
    "\n",
    "# K-Fold cross validation\n",
    "n_folds = 5\n",
    "kfold = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "\n",
    "# Model\n",
    "model = lgb.LGBMClassifier(n_estimators=300, objective='multiclass', eval_metric='multi_error', num_class=9,  nthread= -1, verbose_eval=-1)\n",
    "\n",
    "grid_search = RandomizedSearchCV(model, param_grid, scoring=\"accuracy\", n_jobs=-1, cv=kfold, verbose=1, n_iter=300)\n",
    "result = grid_search.fit(data.values, target['surface'].values)\n",
    "\n",
    "print(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\n",
    "means = result.cv_results_['mean_test_score']\n",
    "stds = result.cv_results_['std_test_score']\n",
    "params = result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's multi_error: 0.000291971\tvalid_1's multi_error: 0.0779221\n",
      "Fold: 0 score: 0.922077922077922\n",
      "Training until validation scores don't improve for 50 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.140625\n",
      "Fold: 1 score: 0.859375\n",
      "Training until validation scores don't improve for 50 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.122715\n",
      "Fold: 2 score: 0.877284595300261\n",
      "Training until validation scores don't improve for 50 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.104712\n",
      "Fold: 3 score: 0.8952879581151832\n",
      "Training until validation scores don't improve for 50 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.104987\n",
      "Fold: 4 score: 0.89501312335958\n",
      "Training until validation scores don't improve for 50 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's multi_error: 0.00058326\tvalid_1's multi_error: 0.107612\n",
      "Fold: 5 score: 0.8923884514435696\n",
      "Training until validation scores don't improve for 50 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.139108\n",
      "Fold: 6 score: 0.8608923884514436\n",
      "Training until validation scores don't improve for 50 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.108179\n",
      "Fold: 7 score: 0.8918205804749341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's multi_error: 0\tvalid_1's multi_error: 0.116402\n",
      "Fold: 8 score: 0.8835978835978836\n",
      "Training until validation scores don't improve for 50 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's multi_error: 0.000582411\tvalid_1's multi_error: 0.087766\n",
      "Fold: 9 score: 0.9122340425531915\n"
     ]
    }
   ],
   "source": [
    "for times, (trn_idx, val_idx) in enumerate(folds.split(data.values,target['surface'].values)):\n",
    "    lgb_train = lgb.Dataset(data.iloc[trn_idx], label=target['surface'][trn_idx])\n",
    "    lgb_val = lgb.Dataset(data.iloc[val_idx], label=target['surface'][val_idx])\n",
    "    params = {\n",
    "    'objective': 'multiclass',\n",
    "    'metric': 'multi_error', \n",
    "    \"num_class\": 9,\n",
    "    'nthread': -1,\n",
    "    'n_estimators': 300,\n",
    "    'max_depth': result.best_params_['max_depth'],\n",
    "    'bagging_fraction': result.best_params_['bagging_fraction'],\n",
    "    'feature_fraction': result.best_params_['feature_fraction'],\n",
    "    'min_data_in_leaf': result.best_params_['min_data_in_leaf'],\n",
    "    'lambda_l1': result.best_params_['lambda_l1'],\n",
    "    'learning_rate': result.best_params_['learning_rate']\n",
    "    }\n",
    "    \n",
    "    model = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_val], early_stopping_rounds=50, verbose_eval=-1)\n",
    "\n",
    "    measured[val_idx] = [np.argmax(x) for x in model.predict(data.iloc[val_idx])]\n",
    "    predicted += model.predict(test)/folds.n_splits\n",
    "    score += (1 - model.best_score['valid_1']['multi_error'])\n",
    "    print(\"Fold: {} score: {}\".format(times, (1 - model.best_score['valid_1']['multi_error'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Accuracy RF 0.8889971945373969\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Avg Accuracy RF', score / folds.n_splits)\n",
    "Y_val_max = measured\n",
    "val_pred = target['surface']\n",
    "labels_names = target['surface'].unique()\n",
    "cnf_matrix = confusion_matrix(Y_val_max, val_pred)\n",
    "cnf_matrix_norm = cnf_matrix.astype('float') / cnf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "df_cm = pd.DataFrame(cnf_matrix_norm, index=labels_names, columns=labels_names)\n",
    "\n",
    "plt.figure(figsize=(20, 7))\n",
    "ax = plt.axes()\n",
    "ax.set_title('Validation')\n",
    "sns.heatmap(df_cm, annot=True, fmt='.2f', cmap=\"Blues\", ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>surface</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hard_tiles_large_space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>carpet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tiled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>carpet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>soft_tiles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   series_id                 surface\n",
       "0          0  hard_tiles_large_space\n",
       "1          1                  carpet\n",
       "2          2                   tiled\n",
       "3          3                  carpet\n",
       "4          4              soft_tiles"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sub = [np.argmax(x) for x in model.predict(test)]\n",
    "sub['surface'] = le.inverse_transform(test_sub)\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
